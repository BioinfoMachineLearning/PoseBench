{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Modes Analysis Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypdb\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from posebench.analysis.inference_analysis import BUST_TEST_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "baseline_methods = [\n",
    "    \"vina_p2rank\",\n",
    "    \"diffdock\",\n",
    "    \"dynamicbind\",\n",
    "    \"neuralplexer\",\n",
    "    \"rfaa\",\n",
    "    \"chai-lab_ss\",\n",
    "    \"chai-lab\",\n",
    "    \"boltz_ss\",\n",
    "    \"boltz\",\n",
    "    \"alphafold3_ss\",\n",
    "    \"alphafold3\",\n",
    "]\n",
    "max_num_repeats_per_method = 3\n",
    "method_max_training_cutoff_date = \"2021-09-30\"\n",
    "\n",
    "datasets = [\"astex_diverse\", \"posebusters_benchmark\", \"dockgen\", \"casp15\"]\n",
    "\n",
    "# PoseBusters Benchmark deposition dates\n",
    "pb_deposition_dates_filepath = \"posebusters_benchmark_complex_pdb_deposition_dates.csv\"\n",
    "assert os.path.exists(\n",
    "    pb_deposition_dates_filepath\n",
    "), \"Please prepare the PoseBusters Benchmark complex PDB deposition dates CSV file via later steps in `failure_modes_analysis_plotting_plinder.ipynb` before proceeding.\"\n",
    "\n",
    "pb_pdb_id_deposition_date_mapping_df = pd.read_csv(pb_deposition_dates_filepath)\n",
    "pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"]\n",
    ")\n",
    "pb_pdb_id_deposition_date_mapping_df = pb_pdb_id_deposition_date_mapping_df[\n",
    "    pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"] > method_max_training_cutoff_date\n",
    "]\n",
    "pb_pdb_id_deposition_date_mapping = dict(\n",
    "    zip(\n",
    "        pb_pdb_id_deposition_date_mapping_df[\"PDB ID\"],\n",
    "        pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"].astype(str),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filepaths for each baseline method\n",
    "globals()[\"vina_output_dir\"] = os.path.join(\"..\", \"forks\", \"Vina\", \"inference\")\n",
    "globals()[\"diffdock_output_dir\"] = os.path.join(\"..\", \"forks\", \"DiffDock\", \"inference\")\n",
    "globals()[\"dynamicbind_output_dir\"] = os.path.join(\n",
    "    \"..\", \"forks\", \"DynamicBind\", \"inference\", \"outputs\", \"results\"\n",
    ")\n",
    "globals()[\"neuralplexer_output_dir\"] = os.path.join(\"..\", \"forks\", \"NeuralPLexer\", \"inference\")\n",
    "globals()[\"rfaa_output_dir\"] = os.path.join(\"..\", \"forks\", \"RoseTTAFold-All-Atom\", \"inference\")\n",
    "globals()[\"chai-lab_output_dir\"] = os.path.join(\"..\", \"forks\", \"chai-lab\", \"inference\")\n",
    "globals()[\"boltz_output_dir\"] = os.path.join(\"..\", \"forks\", \"boltz\", \"inference\")\n",
    "globals()[\"alphafold3_output_dir\"] = os.path.join(\"..\", \"forks\", \"alphafold3\", \"inference\")\n",
    "globals()[\"casp15_output_dir\"] = os.path.join(\"..\", \"data\", \"test_cases\", \"casp15\")\n",
    "for config in [\"\", \"_relaxed\"]:\n",
    "    for dataset in datasets:\n",
    "        for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "            # P2Rank-Vina results\n",
    "            globals()[\n",
    "                f\"vina_p2rank_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"vina_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_vina_p2rank_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"vina_p2rank_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # DiffDock results\n",
    "            globals()[f\"diffdock_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"diffdock_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_diffdock_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"diffdock_{dataset}_output_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # DynamicBind results\n",
    "            globals()[\n",
    "                f\"dynamicbind_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"dynamicbind_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_dynamicbind_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"{dataset}_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # NeuralPLexer results\n",
    "            globals()[\n",
    "                f\"neuralplexer_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"neuralplexer_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_neuralplexer_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"neuralplexer_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # RoseTTAFold-All-Atom results\n",
    "            globals()[f\"rfaa_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"rfaa_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_rfaa_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"rfaa_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Chai-1 (Single-Seq) results\n",
    "            globals()[\n",
    "                f\"chai-lab_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"chai-lab_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_chai-lab_ss_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"chai-lab_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # Chai-1 results\n",
    "            globals()[f\"chai-lab_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"chai-lab_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_chai-lab_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"chai-lab_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Boltz (Single-Seq) results\n",
    "            globals()[f\"boltz_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"boltz_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_boltz_ss_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"boltz_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Boltz results\n",
    "            globals()[f\"boltz_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"boltz_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_boltz_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"boltz_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # AlphaFold 3 (Single-Seq) results\n",
    "            globals()[\n",
    "                f\"alphafold3_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"alphafold3_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_alphafold3_ss_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"alphafold3_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # AlphaFold 3 results\n",
    "            globals()[f\"alphafold3_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"alphafold3_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_alphafold3_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"alphafold3_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Mappings\n",
    "method_mapping = {\n",
    "    \"vina_p2rank\": \"P2Rank-Vina\",\n",
    "    \"diffdock\": \"DiffDock-L\",\n",
    "    \"dynamicbind\": \"DynamicBind\",\n",
    "    \"neuralplexer\": \"NeuralPLexer\",\n",
    "    \"rfaa\": \"RFAA\",\n",
    "    \"chai-lab_ss\": \"Chai-1-Single-Seq\",\n",
    "    \"chai-lab\": \"Chai-1\",\n",
    "    \"boltz_ss\": \"Boltz-1-Single-Seq\",\n",
    "    \"boltz\": \"Boltz-1\",\n",
    "    \"alphafold3_ss\": \"AF3-Single-Seq\",\n",
    "    \"alphafold3\": \"AF3\",\n",
    "}\n",
    "\n",
    "method_category_mapping = {\n",
    "    \"vina_p2rank\": \"Conventional blind\",\n",
    "    \"diffdock\": \"DL-based blind\",\n",
    "    \"dynamicbind\": \"DL-based blind\",\n",
    "    \"neuralplexer\": \"DL-based blind\",\n",
    "    \"rfaa\": \"DL-based blind\",\n",
    "    \"chai-lab_ss\": \"DL-based blind\",\n",
    "    \"chai-lab\": \"DL-based blind\",\n",
    "    \"boltz_ss\": \"DL-based blind\",\n",
    "    \"boltz\": \"DL-based blind\",\n",
    "    \"alphafold3_ss\": \"DL-based blind\",\n",
    "    \"alphafold3\": \"DL-based blind\",\n",
    "}\n",
    "\n",
    "dataset_mapping = {\n",
    "    \"astex_diverse\": \"Astex Diverse set\",\n",
    "    \"posebusters_benchmark\": \"Posebusters Benchmark set\",\n",
    "    \"dockgen\": \"DockGen set\",\n",
    "    \"casp15\": \"CASP15 set\",\n",
    "}\n",
    "\n",
    "casp15_target_pdb_id_mapping = {\n",
    "    # NOTE: `?` indicates that the target's crystal structure is not publicly available\n",
    "    \"H1135\": \"7z8y\",\n",
    "    \"H1171v1\": \"7pbl\",\n",
    "    \"H1171v2\": \"7pbl\",\n",
    "    \"H1172v1\": \"7pbp\",\n",
    "    \"H1172v2\": \"7pbp\",\n",
    "    \"H1172v3\": \"7pbp\",\n",
    "    \"H1172v4\": \"7pbp\",\n",
    "    \"T1124\": \"7ux8\",\n",
    "    \"T1127v2\": \"?\",\n",
    "    \"T1146\": \"?\",\n",
    "    \"T1152\": \"7r1l\",\n",
    "    \"T1158v1\": \"8sx8\",\n",
    "    \"T1158v2\": \"8sxb\",\n",
    "    \"T1158v3\": \"8sx7\",\n",
    "    \"T1158v4\": \"8swn\",\n",
    "    \"T1170\": \"7pbr\",\n",
    "    \"T1181\": \"?\",\n",
    "    \"T1186\": \"?\",\n",
    "    \"T1187\": \"8ad2\",\n",
    "    \"T1188\": \"8c6z\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test results for each baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and report test results for each baseline method\n",
    "for config in [\"\"]:\n",
    "    for dataset in datasets:\n",
    "        for method in baseline_methods:\n",
    "            for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "                method_title = method_mapping[method]\n",
    "\n",
    "                if not os.path.exists(\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "                    ]\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"] = (\n",
    "                    pd.read_csv(\n",
    "                        globals()[\n",
    "                            f\"{method}_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if dataset == \"casp15\":\n",
    "                    # count the number of ligands in each target complex, and assign these corresponding numbers to the ligands (rows) of each complex\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"num_target_ligands\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "                        .groupby([\"target\", \"mdl\"])[\"pose\"]\n",
    "                        .transform(\"count\")\n",
    "                    )\n",
    "\n",
    "                    # filter out non-relevant ligand predictions, and for all methods select only their first model for each ligand\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        np.where(\n",
    "                            (\n",
    "                                globals()[\n",
    "                                    f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                                ].relevant\n",
    "                            ),\n",
    "                            True,\n",
    "                            False,\n",
    "                        )\n",
    "                        & (\n",
    "                            globals()[\n",
    "                                f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                            ].mdl\n",
    "                            == 1\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                    # finalize bust (i.e., scoring) results for CASP15, using dummy values for `pb_valid` and `crmsd_≤_1å`\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"rmsd_≤_2å\"\n",
    "                    ] = (\n",
    "                        globals()[\n",
    "                            f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                        ].loc[:, \"rmsd\"]\n",
    "                        <= 2\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pdb_valid\"\n",
    "                    ] = True\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"crmsd_≤_1å\"\n",
    "                    ] = True\n",
    "\n",
    "                else:\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        BUST_TEST_COLUMNS + [\"rmsd\", \"centroid_distance\", \"mol_id\"]\n",
    "                    ]\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pb_valid\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "                        .iloc[:, 1:-3]\n",
    "                        .all(axis=1)\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"crmsd_≤_1å\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                            \"centroid_distance\"\n",
    "                        ]\n",
    "                        < 1\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pdb_id\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        \"mol_id\"\n",
    "                    ]\n",
    "\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"method\"\n",
    "                ] = method\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"post-processing\"\n",
    "                ] = (\"energy minimization\" if config == \"_relaxed\" else \"none\")\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"dataset\"\n",
    "                ] = dataset\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"docked_ligand_successfully_loaded\"\n",
    "                ] = (\n",
    "                    True\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ][[\"mol_pred_loaded\", \"mol_true_loaded\", \"mol_cond_loaded\"]].all(axis=1)\n",
    "                )\n",
    "\n",
    "                if dataset == \"posebusters_benchmark\":\n",
    "                    # keep only the results for complexes deposited in the PDB after the maximum cutoff date for any method's training data\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        \"pdb_id\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        \"mol_id\"\n",
    "                    ].map(\n",
    "                        lambda x: x.lower().split(\"_\")[0]\n",
    "                    )\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                            \"pdb_id\"\n",
    "                        ].isin(pb_pdb_id_deposition_date_mapping.keys())\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_method_index(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Assign method index for plotting.\n",
    "\n",
    "    :param method: Method name.\n",
    "    :return: Method index.\n",
    "    \"\"\"\n",
    "    return list(method_mapping.keys()).index(method)\n",
    "\n",
    "\n",
    "def categorize_method(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Categorize method for plotting.\n",
    "\n",
    "    :param method: Method name.\n",
    "    :return: Method category.\n",
    "    \"\"\"\n",
    "    return method_category_mapping.get(method, \"Misc\")\n",
    "\n",
    "\n",
    "def subset_counter(\n",
    "    subset_counter: Counter, superset_counter: Counter, normalize_subset: bool = False\n",
    ") -> Counter:\n",
    "    \"\"\"\n",
    "    Subset a superset counter by a subset counter.\n",
    "\n",
    "    :param subset_counter: Subset counter.\n",
    "    :param superset_counter: Superset counter.\n",
    "    :param normalize_subset: Normalize subset counter by superset counter.\n",
    "    :return: Subsetted counter.\n",
    "    \"\"\"\n",
    "    subsetted_counter = Counter()\n",
    "    for key in subset_counter:\n",
    "        if key in superset_counter and superset_counter[key] != 0:\n",
    "            subsetted_counter[key] = (\n",
    "                subset_counter[key] / superset_counter[key]\n",
    "                if normalize_subset\n",
    "                else superset_counter[key]\n",
    "            )\n",
    "        else:\n",
    "            subsetted_counter[key] = 0  # or handle as needed\n",
    "    return subsetted_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and organize the results CSVs\n",
    "for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "    globals()[f\"results_table_{repeat_index}\"] = pd.concat(\n",
    "        [\n",
    "            globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "            for dataset in datasets\n",
    "            for method in baseline_methods\n",
    "            for config in [\"\"]\n",
    "            if f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\" in globals()\n",
    "        ]\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method_category\"] = globals()[\n",
    "        f\"results_table_{repeat_index}\"\n",
    "    ][\"method\"].apply(categorize_method)\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method_assignment_index\"] = globals()[\n",
    "        f\"results_table_{repeat_index}\"\n",
    "    ][\"method\"].apply(assign_method_index)\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"crmsd_within_threshold\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"crmsd_≤_1å\"].fillna(False)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_≤_2å\"].fillna(False)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold_and_pb_valid\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold\"]\n",
    "    ) & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"pb_valid\"].fillna(False))\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"RMSD ≤ 2 Å & PB-Valid\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"rmsd_within_threshold_and_pb_valid\"]\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"cRMSD ≤ 1 Å\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"crmsd_within_threshold\"]\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"RMSD ≤ 2 Å\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"rmsd_within_threshold\"]\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"].map(dataset_mapping)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"].map(method_mapping)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect metadata across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PDB IDs of complexes across all datasets\n",
    "for dataset in datasets:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "            == dataset_mapping[dataset]\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[:, \"pdb_id\"].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of complex types across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of the complexes across all datasets\n",
    "pdb_info_cache = dict()\n",
    "\n",
    "for repeat_index in [1]:  # NOTE: we only consider the first repeat\n",
    "    all_complexes_df = []\n",
    "    for dataset in datasets:\n",
    "        complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_{repeat_index}\"], columns=[\"pdb_id\"]\n",
    "        )\n",
    "        complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        all_complexes_df.append(complexes_df)\n",
    "    all_complexes_df = pd.concat(all_complexes_df, ignore_index=True)\n",
    "\n",
    "    if all_complexes_df.empty:\n",
    "        print(\"No complexes for any dataset.\")\n",
    "        continue\n",
    "\n",
    "    complex_function_annotations = []\n",
    "    for pdb_id in set(all_complexes_df[\"pdb_id\"]):\n",
    "        pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "        if pdb_id == \"?\":\n",
    "            continue\n",
    "        if pdb_id in pdb_info_cache:\n",
    "            pdb_id_info = pdb_info_cache[pdb_id]\n",
    "        else:\n",
    "            pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "            pdb_info_cache[pdb_id] = pdb_id_info\n",
    "        if not pdb_id_info:\n",
    "            continue\n",
    "        complex_function_annotations.append(\n",
    "            # NOTE: these represent functional keywords\n",
    "            pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "\n",
    "    complex_function_annotation_counts = Counter(complex_function_annotations)\n",
    "    df = pd.DataFrame(\n",
    "        complex_function_annotation_counts.items(),\n",
    "        columns=[\"Keyword\", \"Frequency\"],\n",
    "    )\n",
    "    df[\"Frequency\"] = df[\"Frequency\"].astype(int)\n",
    "    df = df.sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.barplot(data=df, x=\"Frequency\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "    max_freq = df[\"Frequency\"].max()\n",
    "    plt.xticks(ticks=range(0, max_freq + 1), labels=range(0, max_freq + 1), rotation=60)\n",
    "\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Complex Annotation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"complexes_functional_keywords_{repeat_index}.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"{len(complex_function_annotations)} complex annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of the PoseBusters Benchmark dataset's complex deposition dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # report the PDB deposition date of each PoseBusters Benchmark complex\n",
    "# posebusters_complex_deposition_dates = dict()\n",
    "# for pdb_id in set(\n",
    "#     all_complexes_df[all_complexes_df[\"dataset\"] == \"Posebusters Benchmark set\"][\"pdb_id\"]\n",
    "# ):\n",
    "#     pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "#     if pdb_id == \"?\":\n",
    "#         continue\n",
    "#     if pdb_id in pdb_info_cache:\n",
    "#         pdb_id_info = pdb_info_cache[pdb_id]\n",
    "#     else:\n",
    "#         pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "#         pdb_info_cache[pdb_id] = pdb_id_info\n",
    "#     if not pdb_id_info:\n",
    "#         continue\n",
    "#     posebusters_complex_deposition_dates[pdb_id] = pdb_id_info[\"rcsb_accession_info\"][\n",
    "#         \"deposit_date\"\n",
    "#     ]\n",
    "\n",
    "# # analyze and plot statistics of the PoseBusters complexes' deposition dates\n",
    "# posebusters_complex_pdb_deposition_dates_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"PDB ID\": posebusters_complex_deposition_dates.keys(),\n",
    "#         \"Deposition Date\": posebusters_complex_deposition_dates.values(),\n",
    "#     }\n",
    "# )\n",
    "# posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "#     posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    "# )\n",
    "# posebusters_complex_pdb_deposition_dates_df.to_csv(\n",
    "#     \"posebusters_benchmark_complex_pdb_deposition_dates.csv\", index=False\n",
    "# )\n",
    "\n",
    "# posebusters_pre_cutoff_complexes = posebusters_complex_pdb_deposition_dates_df[\n",
    "#     posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    "#     <= method_max_training_cutoff_date\n",
    "# ]\n",
    "# posebusters_post_cutoff_complexes = posebusters_complex_pdb_deposition_dates_df[\n",
    "#     posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    "#     > method_max_training_cutoff_date\n",
    "# ]\n",
    "# print(\n",
    "#     f\"{len(posebusters_pre_cutoff_complexes)}/{len(posebusters_complex_pdb_deposition_dates_df)} PoseBusters Benchmark complexes deposited before maximum cutoff of {method_max_training_cutoff_date}.\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"{len(posebusters_post_cutoff_complexes)}/{len(posebusters_complex_pdb_deposition_dates_df)} PoseBusters Benchmark complexes deposited after maximum cutoff of {method_max_training_cutoff_date}.\"\n",
    "# )\n",
    "\n",
    "# sns.histplot(posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"].values, bins=25)\n",
    "# plt.xlabel(\"Deposition Date\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"posebusters_benchmark_complex_pdb_deposition_dates.png\")\n",
    "# plt.show()\n",
    "# plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify failure modes across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PDB IDs of complexes for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by any method\n",
    "for dataset in datasets:\n",
    "    docking_success_column = \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "            == dataset_mapping[dataset]\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_docked_by_any_method_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"{dataset}_complexes_not_docked_by_any_method_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"pdb_id\"].isin(\n",
    "                    globals()[f\"{dataset}_complexes_docked_by_any_method_{repeat_index}\"]\n",
    "                ),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find commonalities among the failure modes of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of the failed complexes across all datasets\n",
    "for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "    all_failed_complexes_df = []\n",
    "    for dataset in datasets:\n",
    "        predicted_complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_not_docked_by_any_method_{repeat_index}\"],\n",
    "            columns=[\"pdb_id\"],\n",
    "        )\n",
    "        predicted_complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        all_failed_complexes_df.append(predicted_complexes_df)\n",
    "    all_failed_complexes_df = pd.concat(all_failed_complexes_df, ignore_index=True)\n",
    "\n",
    "    if all_failed_complexes_df.empty:\n",
    "        print(\"No failed complexes for any dataset.\")\n",
    "        continue\n",
    "\n",
    "    failed_complex_function_annotations = []\n",
    "    for pdb_id in set(all_failed_complexes_df[\"pdb_id\"]):\n",
    "        pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "        if pdb_id == \"?\":\n",
    "            continue\n",
    "        if pdb_id in pdb_info_cache:\n",
    "            pdb_id_info = pdb_info_cache[pdb_id]\n",
    "        else:\n",
    "            pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "            pdb_info_cache[pdb_id] = pdb_id_info\n",
    "        if not pdb_id_info:\n",
    "            continue\n",
    "        failed_complex_function_annotations.append(\n",
    "            # NOTE: these represent functional keywords\n",
    "            pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "\n",
    "    failed_complex_function_annotation_counts = subset_counter(\n",
    "        Counter(failed_complex_function_annotations),\n",
    "        complex_function_annotation_counts,\n",
    "        normalize_subset=True,\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        failed_complex_function_annotation_counts.items(),\n",
    "        columns=[\"Keyword\", \"Failed Ratio\"],\n",
    "    )\n",
    "    df[\"Frequency\"] = df[\"Keyword\"].map(complex_function_annotation_counts)\n",
    "    df.sort_values(\n",
    "        by=[\"Failed Ratio\", \"Frequency\"], ascending=False, inplace=True, ignore_index=True\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df, x=\"Failed Ratio\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "    plt.xlabel(\"Failed Ratio\")\n",
    "    plt.ylabel(\"Complex Annotation\")\n",
    "\n",
    "    plt.xlim(0, 1.1)\n",
    "\n",
    "    # annotate bars with the frequency of each keyword\n",
    "    for index, row in df.iterrows():\n",
    "        plt.text(\n",
    "            x=row[\"Failed Ratio\"] + 0.01,\n",
    "            y=index,\n",
    "            s=f\"{row['Failed Ratio']:.2f} ({row['Frequency']})\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"failed_complexes_functional_keywords_{repeat_index}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"{len(failed_complex_function_annotations)} complex annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify AlphaFold 3's failure modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find complexes that AlphaFold 3 failed to correctly predict\n",
    "for dataset in datasets:\n",
    "    docking_success_column = \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            (\n",
    "                globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "                == dataset_mapping[dataset]\n",
    "            )\n",
    "            & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] == \"AF3\")\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"{dataset}_complexes_not_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"pdb_id\"].isin(\n",
    "                    globals()[f\"{dataset}_complexes_docked_by_af3_{repeat_index}\"]\n",
    "                ),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record and plot AlphaFold 3's failure mode metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of AlphaFold 3's failed complexes across all datasets\n",
    "all_failed_af3_complexes_df = []\n",
    "for dataset in datasets:\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        failed_af3_complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_not_docked_by_af3_{repeat_index}\"],\n",
    "            columns=[\"pdb_id\"],\n",
    "        )\n",
    "        failed_af3_complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        failed_af3_complexes_df[\"repeat_index\"] = repeat_index\n",
    "        all_failed_af3_complexes_df.append(failed_af3_complexes_df)\n",
    "all_failed_af3_complexes_df = pd.concat(all_failed_af3_complexes_df, ignore_index=True)\n",
    "\n",
    "failed_af3_complex_function_annotations = []\n",
    "for pdb_id in set(all_failed_af3_complexes_df[\"pdb_id\"]):\n",
    "    pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "    if pdb_id == \"?\":\n",
    "        continue\n",
    "    if pdb_id in pdb_info_cache:\n",
    "        pdb_id_info = pdb_info_cache[pdb_id]\n",
    "    else:\n",
    "        pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "        pdb_info_cache[pdb_id] = pdb_id_info\n",
    "    if not pdb_id_info:\n",
    "        continue\n",
    "    failed_af3_complex_function_annotations.append(\n",
    "        # NOTE: these represent functional keywords\n",
    "        pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "        .lower()\n",
    "        .split(\", \")[0]\n",
    "    )\n",
    "\n",
    "failed_af3_complex_function_annotation_counts = subset_counter(\n",
    "    Counter(failed_af3_complex_function_annotations),\n",
    "    complex_function_annotation_counts,\n",
    "    normalize_subset=True,\n",
    ")\n",
    "df = pd.DataFrame(\n",
    "    failed_af3_complex_function_annotation_counts.items(),\n",
    "    columns=[\"Keyword\", \"Failed Ratio\"],\n",
    ")\n",
    "df[\"Frequency\"] = df[\"Keyword\"].map(complex_function_annotation_counts)\n",
    "df.sort_values(by=[\"Failed Ratio\", \"Frequency\"], ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=df, x=\"Failed Ratio\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Failed Ratio\")\n",
    "plt.ylabel(\"Complex Annotation\")\n",
    "\n",
    "plt.xlim(0, 1.09)\n",
    "\n",
    "# annotate bars with the frequency of each keyword\n",
    "for index, row in df.iterrows():\n",
    "    plt.text(\n",
    "        x=row[\"Failed Ratio\"] + 0.01,\n",
    "        y=index,\n",
    "        s=f\"{row['Failed Ratio']:.2f} ({row['Frequency']})\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"failed_af3_complexes_functional_keywords.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(f\"{len(failed_af3_complex_function_annotations)} complex annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study PDB statistics of different types of complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all CSV files from a custom PDB report\n",
    "report_types = os.listdir(\"pdb_reports\")\n",
    "\n",
    "for report_type in report_types:\n",
    "    pdb_report_dir = os.path.join(\"pdb_reports\", report_type)\n",
    "    pdb_report_files = [\n",
    "        os.path.join(pdb_report_dir, f) for f in os.listdir(pdb_report_dir) if f.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    pdb_report_dfs = []\n",
    "    for pdb_report_file in pdb_report_files:\n",
    "        pdb_report_dfs.append(pd.read_csv(pdb_report_file, skiprows=1))\n",
    "    pdb_report_df = pd.concat(pdb_report_dfs, ignore_index=True)\n",
    "\n",
    "    # analyze and plot statistics of the custom PDB report\n",
    "    pdb_report_df[\"Refinement Resolution (Å)\"] = pdb_report_df[\"Refinement Resolution (Å)\"].astype(\n",
    "        str\n",
    "    )\n",
    "    pdb_report_df[\"Refinement Resolution (Å)\"] = pd.to_numeric(\n",
    "        pdb_report_df[\"Refinement Resolution (Å)\"].str.replace(\",\", \"\"),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    pdb_report_df[\"Deposition Date\"] = pd.to_datetime(pdb_report_df[\"Deposition Date\"])\n",
    "\n",
    "    pdb_report_df.to_csv(f\"{report_type}_pdb_report.csv\", index=False)\n",
    "\n",
    "    print(f\"{len(pdb_report_df)} PDB entries in the custom {report_type} report.\")\n",
    "\n",
    "    sns.histplot(pdb_report_df[\"Refinement Resolution (Å)\"].values)\n",
    "    plt.xlim(0, 10)\n",
    "    plt.xlabel(\"Refinement Resolution (Å)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{report_type}_pdb_report_resolution.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    sns.histplot(pdb_report_df[\"Deposition Date\"].values)\n",
    "    plt.xlabel(\"Deposition Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{report_type}_pdb_report_deposition_date.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### Study AlphaFold 3's relationship between training-test set ligand-binding pocket structural overlap and structure prediction performance -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot correlation between performance of method predictions for PoseBusters Benchmark set complexes and their maximum similarity to the PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare max (training set) ligand-binding pocket structural overlap and (test set) RMSD of each method's predicted PoseBusters Benchmark set complexes\n",
    "af3_overlap_datasets = [\"posebusters_benchmark\"]\n",
    "\n",
    "all_predicted_complexes_df = []\n",
    "for dataset in af3_overlap_datasets:\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        predicted_complexes_df = copy.deepcopy(\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "                (\n",
    "                    globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "                    == dataset_mapping[dataset]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        predicted_complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        predicted_complexes_df[\"repeat_index\"] = repeat_index\n",
    "        all_predicted_complexes_df.append(predicted_complexes_df)\n",
    "all_predicted_complexes_df = pd.concat(all_predicted_complexes_df, ignore_index=True)\n",
    "all_predicted_complex_pdb_ids = list(all_predicted_complexes_df.loc[:, \"pdb_id\"].unique())\n",
    "\n",
    "# analyze and plot statistics of each method's predictions and the novelty of the target binding modes\n",
    "pb_pdb_id_ccd_code_mapping = {\n",
    "    pdb_ccd_code.split(\"_\")[0]: pdb_ccd_code.split(\"_\")[1]\n",
    "    for pdb_ccd_code in os.listdir(os.path.join(\"..\", \"data\", \"posebusters_benchmark_set\"))\n",
    "    if os.path.isdir(os.path.join(\"..\", \"data\", \"posebusters_benchmark_set\", pdb_ccd_code))\n",
    "    if pdb_ccd_code.split(\"_\")[0].lower() in all_predicted_complex_pdb_ids\n",
    "    and not any(s in pdb_ccd_code for s in [\"plots\", \"msas\", \"structures\"])\n",
    "}\n",
    "\n",
    "# load annotations from CSV\n",
    "annotated_df = pd.read_csv(os.path.join(\"..\", \"data\", \"plinder\", \"annotations.csv\"))\n",
    "annotated_df[\"target_release_date\"] = pd.to_datetime(annotated_df[\"target_release_date\"])\n",
    "\n",
    "# filter annotated_df to rows where (entry_pdb_id, ligand_ccd_code) matches pb_pdb_id_ccd_code_mapping\n",
    "annotated_df = annotated_df[\n",
    "    annotated_df.apply(\n",
    "        lambda row: (\n",
    "            (row[\"entry_pdb_id\"].upper(), row[\"ligand_ccd_code\"])\n",
    "            in pb_pdb_id_ccd_code_mapping.items()\n",
    "        )\n",
    "        and not pd.isna(row[\"target_system\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "# ensure the key columns match in format\n",
    "predicted_complexes_df[\"pdb_id\"] = predicted_complexes_df[\"pdb_id\"].str.upper()\n",
    "annotated_df[\"entry_pdb_id\"] = annotated_df[\"entry_pdb_id\"].str.upper()\n",
    "\n",
    "# merge RMSD values into annotated_df\n",
    "annotated_df = annotated_df.merge(\n",
    "    predicted_complexes_df[[\"pdb_id\", \"method\", \"rmsd\"]],\n",
    "    left_on=\"entry_pdb_id\",\n",
    "    right_on=\"pdb_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "def remove_rmsd_outliers(df: pd.DataFrame, col: str = \"rmsd\", factor: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"Remove outliers from a DataFrame column.\"\"\"\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - factor * iqr\n",
    "    upper_bound = q3 + factor * iqr\n",
    "    return df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "# drop rows with missing or outlier values\n",
    "method_generalization_df = annotated_df[[\"sucos_shape_pocket_qcov\", \"method\", \"rmsd\"]].dropna()\n",
    "method_generalization_df = remove_rmsd_outliers(method_generalization_df)\n",
    "\n",
    "# --- compute per-method correlations (use all points for stats) ---\n",
    "method_corrs = []\n",
    "for method_name, df_method in method_generalization_df.groupby(\"method\"):\n",
    "    if len(df_method) < 3:\n",
    "        continue\n",
    "    pr, pp = pearsonr(df_method[\"sucos_shape_pocket_qcov\"], df_method[\"rmsd\"])\n",
    "    sr, sp = spearmanr(df_method[\"sucos_shape_pocket_qcov\"], df_method[\"rmsd\"])\n",
    "    method_corrs.append(\n",
    "        {\n",
    "            \"method\": method_name,\n",
    "            \"pearson_r\": pr,\n",
    "            \"pearson_p\": pp,\n",
    "            \"spearman_r\": sr,\n",
    "            \"spearman_p\": sp,\n",
    "            \"n\": len(df_method),\n",
    "        }\n",
    "    )\n",
    "\n",
    "corr_df = pd.DataFrame(method_corrs)\n",
    "if corr_df.empty:\n",
    "    raise ValueError(\"No methods have >= 3 points; nothing to plot.\")\n",
    "\n",
    "# --- split positive vs negative Pearson r ---\n",
    "# pos_df = corr_df[corr_df[\"pearson_r\"] >= 0].sort_values(\"pearson_r\", ascending=False)\n",
    "# neg_df = corr_df[corr_df[\"pearson_r\"] < 0].sort_values(\"pearson_r\")\n",
    "\n",
    "neg_df = corr_df.sort_values(\"pearson_r\")\n",
    "\n",
    "# pos_methods = pos_df[\"method\"].tolist()\n",
    "neg_methods = neg_df[\"method\"].tolist()\n",
    "\n",
    "# --- determine clipping to ignore extreme RMSD values for axis scaling ---\n",
    "ymax = np.percentile(method_generalization_df[\"rmsd\"], 95)\n",
    "ymin = max(0.0, method_generalization_df[\"rmsd\"].min())\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "# ax_pos, ax_neg = axes\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6), sharey=True)\n",
    "ax_neg = axes\n",
    "\n",
    "\n",
    "def plot_group(ax, methods, corr_subdf):\n",
    "    if not methods:\n",
    "        ax.text(0.5, 0.5, \"No methods in this group\", ha=\"center\", va=\"center\")\n",
    "        ax.set_xlabel(\"SuCOS-pocket similarity\")\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "        return\n",
    "\n",
    "    palette = sns.color_palette(n_colors=len(methods))\n",
    "    for i, method in enumerate(methods):\n",
    "        dfm = method_generalization_df[method_generalization_df[\"method\"] == method]\n",
    "        color = palette[i]\n",
    "        # scatter points\n",
    "        sns.scatterplot(\n",
    "            data=dfm,\n",
    "            x=\"sucos_shape_pocket_qcov\",\n",
    "            y=\"rmsd\",\n",
    "            ax=ax,\n",
    "            label=method,\n",
    "            color=color,\n",
    "            alpha=0.5,\n",
    "            s=40,\n",
    "        )\n",
    "        # regression line (no scatter here)\n",
    "        sns.regplot(\n",
    "            data=dfm,\n",
    "            x=\"sucos_shape_pocket_qcov\",\n",
    "            y=\"rmsd\",\n",
    "            ax=ax,\n",
    "            scatter=False,\n",
    "            ci=None,\n",
    "            color=color,\n",
    "            line_kws={\"lw\": 2},\n",
    "        )\n",
    "        # mark outliers that were clipped for axis scaling\n",
    "        out = dfm[dfm[\"rmsd\"] > ymax]\n",
    "        if not out.empty:\n",
    "            ax.scatter(\n",
    "                out[\"sucos_shape_pocket_qcov\"],\n",
    "                [ymax] * len(out),\n",
    "                marker=\"^\",\n",
    "                s=60,\n",
    "                edgecolor=\"k\",\n",
    "                linewidth=0.5,\n",
    "                color=color,\n",
    "                alpha=0.85,\n",
    "            )\n",
    "\n",
    "    ax.set_xlabel(\"SuCOS-pocket similarity\")\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.legend(fontsize=8, loc=\"upper left\")\n",
    "\n",
    "    # correlation table for this panel\n",
    "    text_lines = [\n",
    "        f\"{r['method']}: r={r['pearson_r']:.2f} (p={r['pearson_p']:.1g}), ρ={r['spearman_r']:.2f}\"\n",
    "        for _, r in corr_subdf.iterrows()\n",
    "    ]\n",
    "    ax.text(\n",
    "        0.98,\n",
    "        0.98,  # near top-right\n",
    "        \"\\n\".join(text_lines),\n",
    "        fontsize=9,\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,  # position in axes coordinates\n",
    "        bbox=dict(facecolor=\"white\", edgecolor=\"gray\", boxstyle=\"round,pad=0.3\"),\n",
    "    )\n",
    "\n",
    "\n",
    "# plot_group(ax_pos, pos_methods, pos_df)\n",
    "# # ax_pos.set_title(\"Methods with positive Pearson r\")\n",
    "# ax_pos.set_ylabel(\"RMSD\")\n",
    "\n",
    "\n",
    "plot_group(ax_neg, neg_methods, neg_df)\n",
    "# ax_neg.set_title(\"Methods with negative Pearson r\")\n",
    "# ax_neg.set_ylabel(\"\")  # shared y-label on left\n",
    "ax_neg.set_ylabel(\"RMSD\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"posebusters_benchmark_methods_generalization_analysis.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# print sorted summary to console\n",
    "print(corr_df.sort_values(\"pearson_r\", ascending=False).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoseBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
