{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASP15 Method Interaction Analysis Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess  # nosec\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from beartype import beartype\n",
    "from beartype.typing import Any, Literal\n",
    "from Bio.PDB import PDBIO, PDBParser, Select\n",
    "from posecheck import PoseCheck\n",
    "from rdkit import Chem\n",
    "from scipy.stats import ttest_rel, wasserstein_distance\n",
    "from tqdm import tqdm\n",
    "from wrapt_timeout_decorator import timeout\n",
    "\n",
    "from posebench.utils.data_utils import count_num_residues_in_pdb_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "baseline_methods = [\n",
    "    \"vina_p2rank\",\n",
    "    \"diffdock\",\n",
    "    \"dynamicbind\",\n",
    "    \"rfaa\",\n",
    "    \"chai-lab_ss\",\n",
    "    \"chai-lab\",\n",
    "    \"alphafold3_ss\",\n",
    "    \"alphafold3\",\n",
    "    \"neuralplexer3_ss\",\n",
    "    \"neuralplexer3\",\n",
    "]\n",
    "max_num_repeats_per_method = (\n",
    "    1  # NOTE: Here, to simplify the analysis, we only consider the first run of each method\n",
    ")\n",
    "\n",
    "casp15_set_dir = os.path.join(\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"casp15_set\",\n",
    "    \"targets\",\n",
    ")\n",
    "assert os.path.exists(\n",
    "    casp15_set_dir\n",
    "), \"Please download the (public) CASP15 set from `https://zenodo.org/records/13858866` before proceeding.\"\n",
    "\n",
    "# Mappings\n",
    "method_mapping = {\n",
    "    \"vina_p2rank\": \"P2Rank-Vina\",\n",
    "    \"diffdock\": \"DiffDock-L\",\n",
    "    \"dynamicbind\": \"DynamicBind\",\n",
    "    \"rfaa\": \"RoseTTAFold-AA\",\n",
    "    \"chai-lab_ss\": \"Chai-1-Single-Seq\",\n",
    "    \"chai-lab\": \"Chai-1\",\n",
    "    \"alphafold3_ss\": \"AF3-Single-Seq\",\n",
    "    \"alphafold3\": \"AF3\",\n",
    "    \"neuralplexer3_ss\": \"NP3-Single-Seq\",\n",
    "    \"neuralplexer3\": \"NP3\",\n",
    "}\n",
    "\n",
    "CASP15_ANALYSIS_TARGETS_TO_SKIP = [\n",
    "    \"T1170\"\n",
    "]  # NOTE: these will be skipped since they were not scoreable\n",
    "MAX_CASP15_ANALYSIS_PROTEIN_SEQUENCE_LENGTH = (\n",
    "    2000  # Only CASP15 targets with protein sequences below this threshold can be analyzed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinSelect(Select):\n",
    "    \"\"\"A class to select only protein residues from a PDB file.\"\"\"\n",
    "\n",
    "    def accept_residue(self, residue: Any):\n",
    "        \"\"\"\n",
    "        Only accept residues that are part of a protein (e.g., standard amino acids).\n",
    "\n",
    "        :param residue: The residue to check.\n",
    "        :return: True if the residue is part of a protein, False otherwise.\n",
    "        \"\"\"\n",
    "        return residue.id[0] == \" \"  # NOTE: `HETATM` flag must be a blank for protein residues\n",
    "\n",
    "\n",
    "class LigandSelect(Select):\n",
    "    \"\"\"A class to select only ligand residues from a PDB file.\"\"\"\n",
    "\n",
    "    def accept_residue(self, residue: Any):\n",
    "        \"\"\"\n",
    "        Only accept residues that are part of a ligand.\n",
    "\n",
    "        :param residue: The residue to check.\n",
    "        :return: True if the residue is part of a ligand, False otherwise.\n",
    "        \"\"\"\n",
    "        return residue.id[0] != \" \"  # NOTE: `HETATM` flag must be a filled for ligand residues\n",
    "\n",
    "\n",
    "@beartype\n",
    "def create_temp_pdb_with_only_molecule_type_residues(\n",
    "    input_pdb_filepath: str,\n",
    "    molecule_type: Literal[\"protein\", \"ligand\"],\n",
    "    add_element_types: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a temporary PDB file with only residues of a chosen molecule type.\n",
    "\n",
    "    :param input_pdb_filepath: The input PDB file path.\n",
    "    :param molecule_type: The molecule type to keep (either \"protein\" or \"ligand\").\n",
    "    :param add_element_types: Whether to add element types to the atoms.\n",
    "    :return: The temporary PDB file path.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(molecule_type, input_pdb_filepath)\n",
    "\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "\n",
    "    # create a temporary PDB filepdb_name\n",
    "    temp_pdb_filepath = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdb\")\n",
    "    io.save(\n",
    "        temp_pdb_filepath.name, ProteinSelect() if molecule_type == \"protein\" else LigandSelect()\n",
    "    )\n",
    "\n",
    "    if add_element_types:\n",
    "        with open(temp_pdb_filepath.name.replace(\".pdb\", \"_elem.pdb\"), \"w\") as f:\n",
    "            subprocess.run(  # nosec\n",
    "                f\"pdb_element {temp_pdb_filepath.name}\",\n",
    "                shell=True,\n",
    "                check=True,\n",
    "                stdout=f,\n",
    "            )\n",
    "        shutil.move(temp_pdb_filepath.name.replace(\".pdb\", \"_elem.pdb\"), temp_pdb_filepath.name)\n",
    "\n",
    "    return temp_pdb_filepath.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute interaction fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze `CASP15` set interactions as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"casp15_interaction_dataframes.h5\"):\n",
    "    casp15_protein_ligand_complex_filepaths = []\n",
    "    for item in os.listdir(casp15_set_dir):\n",
    "        item_path = os.path.join(casp15_set_dir, item)\n",
    "        if item.endswith(\"_lig.pdb\") and item.split(\"_\")[0] not in CASP15_ANALYSIS_TARGETS_TO_SKIP:\n",
    "            casp15_protein_ligand_complex_filepaths.append(item_path)\n",
    "\n",
    "    pc = PoseCheck()\n",
    "    casp15_protein_ligand_interaction_dfs = []\n",
    "    for protein_ligand_complex_filepath in tqdm(\n",
    "        casp15_protein_ligand_complex_filepaths, desc=\"Processing CASP15 set\"\n",
    "    ):\n",
    "        try:\n",
    "            temp_protein_filepath = create_temp_pdb_with_only_molecule_type_residues(\n",
    "                protein_ligand_complex_filepath, molecule_type=\"protein\"\n",
    "            )\n",
    "            num_residues_in_target_protein = count_num_residues_in_pdb_file(temp_protein_filepath)\n",
    "            if num_residues_in_target_protein > MAX_CASP15_ANALYSIS_PROTEIN_SEQUENCE_LENGTH:\n",
    "                print(\n",
    "                    f\"CASP15 target {protein_ligand_complex_filepath} has too many protein residues ({num_residues_in_target_protein} > {MAX_CASP15_ANALYSIS_PROTEIN_SEQUENCE_LENGTH}) for `MDAnalysis` to fit into CPU memory. Skipping...\"\n",
    "                )\n",
    "                continue\n",
    "            temp_ligand_filepath = create_temp_pdb_with_only_molecule_type_residues(\n",
    "                protein_ligand_complex_filepath, molecule_type=\"ligand\"\n",
    "            )\n",
    "            ligand_mol = Chem.MolFromPDBFile(temp_ligand_filepath)\n",
    "            pc.load_protein_from_pdb(temp_protein_filepath)\n",
    "            pc.load_ligands_from_mols(\n",
    "                Chem.GetMolFrags(ligand_mol, asMols=True, sanitizeFrags=False)\n",
    "            )\n",
    "            casp15_protein_ligand_interaction_df = timeout(dec_timeout=600)(\n",
    "                pc.calculate_interactions\n",
    "            )(n_jobs=1)\n",
    "            casp15_protein_ligand_interaction_df[\"target\"] = os.path.basename(\n",
    "                protein_ligand_complex_filepath\n",
    "            ).split(\"_lig\")[0]\n",
    "            casp15_protein_ligand_interaction_dfs.append(casp15_protein_ligand_interaction_df)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error processing CASP15 target {protein_ligand_complex_filepath} due to: {e}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # NOTE: we iteratively save the interaction dataframes to an HDF5 file\n",
    "        with pd.HDFStore(\"casp15_interaction_dataframes.h5\") as store:\n",
    "            for i, df in enumerate(casp15_protein_ligand_interaction_dfs):\n",
    "                store.put(f\"df_{i}\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze interactions of each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and cache CASP15 interaction statistics for each baseline method\n",
    "dataset = \"casp15\"\n",
    "\n",
    "for method in baseline_methods:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        method_title = method_mapping[method]\n",
    "\n",
    "        if not os.path.exists(f\"{method}_{dataset}_interaction_dataframes_{repeat_index}.h5\"):\n",
    "            method_casp15_set_dir = os.path.join(\n",
    "                \"..\",\n",
    "                \"data\",\n",
    "                \"test_cases\",\n",
    "                \"casp15\",\n",
    "                f\"top_{method}{'' if 'ensemble' in method else '_ensemble'}_predictions_{repeat_index}\",\n",
    "            )\n",
    "\n",
    "            casp15_protein_ligand_complex_filepaths = []\n",
    "            for item in os.listdir(method_casp15_set_dir):\n",
    "                item_path = os.path.join(method_casp15_set_dir, item)\n",
    "                if (\n",
    "                    item.split(\"_\")[0] not in CASP15_ANALYSIS_TARGETS_TO_SKIP\n",
    "                    and os.path.isdir(item_path)\n",
    "                    and \"_relaxed\" not in item\n",
    "                ):\n",
    "                    protein_pdb_filepath, ligand_sdf_filepath = None, None\n",
    "                    complex_filepaths = glob.glob(\n",
    "                        os.path.join(item_path, \"*rank1*.pdb\")\n",
    "                    ) + glob.glob(os.path.join(item_path, \"*rank1*.sdf\"))\n",
    "                    for file in complex_filepaths:\n",
    "                        if file.endswith(\".pdb\"):\n",
    "                            protein_pdb_filepath = file\n",
    "                        elif file.endswith(\".sdf\"):\n",
    "                            ligand_sdf_filepath = file\n",
    "                    if protein_pdb_filepath is not None and ligand_sdf_filepath is not None:\n",
    "                        casp15_protein_ligand_complex_filepaths.append(\n",
    "                            (protein_pdb_filepath, ligand_sdf_filepath)\n",
    "                        )\n",
    "                    else:\n",
    "                        raise FileNotFoundError(\n",
    "                            f\"Could not find `rank1` protein-ligand complex files for {item}\"\n",
    "                        )\n",
    "\n",
    "            pc = PoseCheck()\n",
    "            casp15_protein_ligand_interaction_dfs = []\n",
    "            for protein_ligand_complex_filepath in tqdm(\n",
    "                casp15_protein_ligand_complex_filepaths,\n",
    "                desc=f\"Processing interactions for {method_title}\",\n",
    "            ):\n",
    "                protein_filepath, ligand_filepath = protein_ligand_complex_filepath\n",
    "                casp15_target = os.path.basename(os.path.dirname(protein_filepath))\n",
    "                print(f\"Processing {method_title} target {casp15_target}...\")\n",
    "                try:\n",
    "                    temp_protein_filepath = create_temp_pdb_with_only_molecule_type_residues(\n",
    "                        protein_filepath, molecule_type=\"protein\", add_element_types=True\n",
    "                    )\n",
    "                    num_residues_in_target_protein = count_num_residues_in_pdb_file(\n",
    "                        temp_protein_filepath\n",
    "                    )\n",
    "                    if (\n",
    "                        num_residues_in_target_protein\n",
    "                        > MAX_CASP15_ANALYSIS_PROTEIN_SEQUENCE_LENGTH\n",
    "                    ):\n",
    "                        print(\n",
    "                            f\"{method_title} target {casp15_target} has too many protein residues ({num_residues_in_target_protein} > {MAX_CASP15_ANALYSIS_PROTEIN_SEQUENCE_LENGTH}) for `MDAnalysis` to fit into CPU memory. Skipping...\"\n",
    "                        )\n",
    "                        continue\n",
    "                    ligand_mol = Chem.MolFromMolFile(ligand_filepath)\n",
    "                    pc.load_protein_from_pdb(temp_protein_filepath)\n",
    "                    pc.load_ligands_from_mols(\n",
    "                        Chem.GetMolFrags(ligand_mol, asMols=True, sanitizeFrags=False)\n",
    "                    )\n",
    "                    casp15_protein_ligand_interaction_df = timeout(\n",
    "                        dec_timeout=600, use_signals=False\n",
    "                    )(pc.calculate_interactions)(n_jobs=1)\n",
    "                    casp15_protein_ligand_interaction_df[\"target\"] = casp15_target\n",
    "                    casp15_protein_ligand_interaction_dfs.append(\n",
    "                        casp15_protein_ligand_interaction_df\n",
    "                    )\n",
    "                    gc.collect()\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Error processing {method_title} target {casp15_target} due to: {e}. Skipping...\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # NOTE: we iteratively save the interaction dataframes to an HDF5 file\n",
    "                with pd.HDFStore(\n",
    "                    f\"{method}_{dataset}_interaction_dataframes_{repeat_index}.h5\"\n",
    "                ) as store:\n",
    "                    for i, df in enumerate(casp15_protein_ligand_interaction_dfs):\n",
    "                        store.put(f\"df_{i}\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot interaction statistics for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "\n",
    "# define a function to process each method\n",
    "def process_method(file_path, category):\n",
    "    interactions = []\n",
    "    with pd.HDFStore(file_path) as store:\n",
    "        for key in store.keys():\n",
    "            for row_index in range(len(store[key])):\n",
    "                interaction_types = [\n",
    "                    interaction[2]\n",
    "                    for interaction in store[key].iloc[row_index].keys().tolist()\n",
    "                    if interaction[2]  # NOTE: this excludes the `target` column's singular value\n",
    "                ]\n",
    "                num_hb_acceptors = interaction_types.count(\"HBAcceptor\")\n",
    "                num_hb_donors = interaction_types.count(\"HBDonor\")\n",
    "                num_vdw_contacts = interaction_types.count(\"VdWContact\")\n",
    "                num_hydrophobic = interaction_types.count(\"Hydrophobic\")\n",
    "                interactions.append(\n",
    "                    {\n",
    "                        \"Hydrogen Bond Acceptors\": num_hb_acceptors,\n",
    "                        \"Hydrogen Bond Donors\": num_hb_donors,\n",
    "                        \"Van der Waals Contacts\": num_vdw_contacts,\n",
    "                        \"Hydrophobic Interactions\": num_hydrophobic,\n",
    "                    }\n",
    "                )\n",
    "    df_rows = []\n",
    "    for interaction in interactions:\n",
    "        for interaction_type, num_interactions in interaction.items():\n",
    "            df_rows.append(\n",
    "                {\n",
    "                    \"Category\": category,\n",
    "                    \"InteractionType\": interaction_type,\n",
    "                    \"NumInteractions\": num_interactions,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(df_rows)\n",
    "\n",
    "\n",
    "# load data from files\n",
    "for method in baseline_methods:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        method_title = method_mapping[method]\n",
    "        file_path = f\"{method}_casp15_interaction_dataframes_{repeat_index}.h5\"\n",
    "        if os.path.exists(file_path):\n",
    "            dfs.append(process_method(file_path, method_title))\n",
    "\n",
    "if os.path.exists(\"casp15_interaction_dataframes.h5\"):\n",
    "    dfs.append(process_method(\"casp15_interaction_dataframes.h5\", \"Reference\"))\n",
    "\n",
    "# combine statistics\n",
    "assert len(dfs) > 0, \"No interaction dataframes found.\"\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# define font properties\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "\n",
    "# plot statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(34, 14), sharey=False)\n",
    "\n",
    "interaction_types = [\n",
    "    \"Hydrogen Bond Acceptors\",\n",
    "    \"Hydrogen Bond Donors\",\n",
    "    \"Van der Waals Contacts\",\n",
    "    \"Hydrophobic Interactions\",\n",
    "]\n",
    "plot_types = [\"box\", \"box\", \"violin\", \"violin\"]\n",
    "\n",
    "for ax, interaction, plot_type in zip(axes.flatten(), interaction_types, plot_types):\n",
    "    data = df[df[\"InteractionType\"] == interaction]\n",
    "\n",
    "    if plot_type == \"box\":\n",
    "        sns.boxplot(data=data, x=\"Category\", y=\"NumInteractions\", ax=ax, showfliers=True)\n",
    "        sns.stripplot(\n",
    "            data=data,\n",
    "            x=\"Category\",\n",
    "            y=\"NumInteractions\",\n",
    "            ax=ax,\n",
    "            color=\"black\",\n",
    "            alpha=0.3,\n",
    "            jitter=True,\n",
    "        )\n",
    "    elif plot_type == \"violin\":\n",
    "        sns.violinplot(data=data, x=\"Category\", y=\"NumInteractions\", ax=ax)\n",
    "        sns.stripplot(\n",
    "            data=data,\n",
    "            x=\"Category\",\n",
    "            y=\"NumInteractions\",\n",
    "            ax=ax,\n",
    "            color=\"black\",\n",
    "            alpha=0.3,\n",
    "            jitter=True,\n",
    "        )\n",
    "\n",
    "    ax.set_title(interaction)\n",
    "    ax.set_ylabel(\"No. Interactions\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"casp15_method_interaction_analysis.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot interaction metrics for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "\n",
    "# define helper functions\n",
    "def split_string_at_numeric(s: str) -> list:\n",
    "    \"\"\"Split a string at numeric characters.\"\"\"\n",
    "    return re.split(r\"\\d+\", s)\n",
    "\n",
    "\n",
    "def bin_interactions(file_path, category):\n",
    "    \"\"\"Bin interactions for each target.\"\"\"\n",
    "    interactions = defaultdict(list)\n",
    "    with pd.HDFStore(file_path) as store:\n",
    "        for key in store.keys():\n",
    "            for row_index in range(len(store[key])):\n",
    "                target = store[key].iloc[row_index][\"target\"]\n",
    "                if not isinstance(target, str):\n",
    "                    target = target.values[0]\n",
    "\n",
    "                try:\n",
    "                    interactions[target].extend(\n",
    "                        [\n",
    "                            # NOTE: we use the `UNL` prefix to denote \"unspecified\" ligand types,\n",
    "                            # since ProLIF cannot differentiate between ligand types for method predictions\n",
    "                            f\"UNL:{split_string_at_numeric(row[1])[0]}:{row[2]}\"\n",
    "                            # f\"{split_string_at_numeric(row[0])[0]}:{split_string_at_numeric(row[1])[0]}:{row[2]}\"\n",
    "                            for row in store[key].iloc[row_index].index.values[:-1]\n",
    "                        ]\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Error processing {key} row {row_index} for target {target} due to: {e}. Skipping...\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "    df_rows = []\n",
    "    for target in interactions:\n",
    "        target_interactions = interactions[target]\n",
    "        target_interactions_histogram = defaultdict(int)\n",
    "        for target_interaction in target_interactions:\n",
    "            target_interactions_histogram[target_interaction] += 1\n",
    "\n",
    "        df_rows.append(\n",
    "            {\n",
    "                \"Category\": category,\n",
    "                \"Target\": target,\n",
    "                \"Interactions_Histogram\": target_interactions_histogram,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(df_rows)\n",
    "\n",
    "\n",
    "def histogram_to_vector(histogram, bins):\n",
    "    \"\"\"Convert a histogram dictionary to a vector aligned with bins.\"\"\"\n",
    "    return np.array([histogram.get(bin, 0) for bin in bins])\n",
    "\n",
    "\n",
    "# load data from files\n",
    "for method in baseline_methods:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        method_title = method_mapping[method]\n",
    "        file_path = f\"{method}_casp15_interaction_dataframes_{repeat_index}.h5\"\n",
    "        if os.path.exists(file_path):\n",
    "            dfs.append(bin_interactions(file_path, method_title))\n",
    "\n",
    "assert os.path.exists(\n",
    "    \"casp15_interaction_dataframes.h5\"\n",
    "), \"No reference interaction dataframe found.\"\n",
    "reference_df = bin_interactions(\"casp15_interaction_dataframes.h5\", \"Reference\")\n",
    "\n",
    "# combine bins from all method dataframes\n",
    "assert len(dfs) > 0, \"No interaction dataframes found.\"\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "emd_values = []\n",
    "for method in df[\"Category\"].unique():\n",
    "    for target in reference_df[\"Target\"]:\n",
    "        # step 1: extract unique bins for each pair of method and reference histograms\n",
    "        method_histogram = df[(df[\"Category\"] == method) & (df[\"Target\"] == target)][\n",
    "            \"Interactions_Histogram\"\n",
    "        ]\n",
    "        reference_histogram = reference_df[reference_df[\"Target\"] == target][\n",
    "            \"Interactions_Histogram\"\n",
    "        ]\n",
    "        if method_histogram.empty:\n",
    "            # NOTE: if a method does not have any ProLIF-parseable interactions\n",
    "            # for a target, we skip-penalize it with a null EMD value\n",
    "            emd_values.append({\"Category\": method, \"Target\": target, \"EMD\": np.nan})\n",
    "            continue\n",
    "        if reference_histogram.empty:\n",
    "            # NOTE: if a target does not have any ProLIF-parseable interactions\n",
    "            # in the reference data, we skip this target\n",
    "            print(\n",
    "                f\"Skipping target {target} for method {method} due to missing reference interaction data.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # NOTE: collecting bins from both histograms allows us to penalize \"hallucinated\" interactions\n",
    "        all_bins = set(method_histogram.values[0].keys()) | set(\n",
    "            reference_histogram.values[0].keys()\n",
    "        )\n",
    "        all_bins = sorted(all_bins)  # keep bins in a fixed order for consistency\n",
    "\n",
    "        # step 2: convert histograms to aligned vectors\n",
    "        method_histogram_vector = method_histogram.apply(\n",
    "            lambda h: histogram_to_vector(h, all_bins)\n",
    "        ).squeeze()\n",
    "        reference_histogram_vector = reference_histogram.apply(\n",
    "            lambda h: histogram_to_vector(h, all_bins)\n",
    "        ).squeeze()\n",
    "\n",
    "        # step 3: compute the EMD values of each method's PLIF histograms\n",
    "        try:\n",
    "            emd = wasserstein_distance(method_histogram_vector, reference_histogram_vector)\n",
    "        except Exception as e:\n",
    "            emd = np.nan\n",
    "            print(f\"Skipping EMD computation for {method} target {target} due to: {e}\")\n",
    "\n",
    "        emd_values.append(\n",
    "            {\n",
    "                \"Category\": method,\n",
    "                \"Target\": target,\n",
    "                \"EMD\": emd,\n",
    "                \"Method_Histogram\": dict(sorted(method_histogram.values[0].items())),\n",
    "                \"Reference_Histogram\": dict(sorted(reference_histogram.values[0].items())),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# plot the EMD and WM values for each method\n",
    "all_emd_values = [\n",
    "    min(50.0, entry[\"EMD\"]) for entry in emd_values\n",
    "]  # clip EMD values to 50.0 when constructing WM values\n",
    "min_emd = np.nanmin(all_emd_values)\n",
    "max_emd = np.nanmax(all_emd_values)\n",
    "for entry in emd_values:\n",
    "    # NOTE: we normalize the EMD values to the range `[0, 1]`\n",
    "    # to compute the Wasserstein Matching (WM) metric while\n",
    "    # ensuring missing predictions are maximally skip-penalized\n",
    "    emd = max_emd if np.isnan(entry[\"EMD\"]).item() else min(50.0, entry[\"EMD\"])\n",
    "    normalized_score = 1 - (emd - min_emd) / (max_emd - min_emd)\n",
    "    entry[\"WM\"] = normalized_score\n",
    "\n",
    "emd_values_df = pd.DataFrame(\n",
    "    emd_values,\n",
    "    columns=[\"Category\", \"Target\", \"EMD\", \"WM\", \"Method_Histogram\", \"Reference_Histogram\"],\n",
    ")\n",
    "emd_values_df.to_csv(\"casp15_plif_metrics.csv\")\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(data=emd_values_df, x=\"Category\", y=\"EMD\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"PLIF-EMD\")\n",
    "plt.savefig(\"casp15_plif_emd_values.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(data=emd_values_df, x=\"Category\", y=\"WM\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"PLIF-WM\")\n",
    "plt.savefig(\"casp15_plif_wm_values.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which types of interactions are most difficult to reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis: the most structured types of interactions (e.g., HBAcceptor, HBDonor) are more difficult to reproduce than unstructured types (e.g., VdWContact, Hydrophobic)\n",
    "struct_emd_values = []\n",
    "for _, row in emd_values_df.iterrows():\n",
    "    method = row[\"Category\"]\n",
    "    target = row[\"Target\"]\n",
    "\n",
    "    method_histogram = row[\"Method_Histogram\"]\n",
    "    reference_histogram = row[\"Reference_Histogram\"]\n",
    "\n",
    "    if method_histogram is np.nan or reference_histogram is np.nan:\n",
    "        continue\n",
    "\n",
    "    # NOTE: collecting bins from both histograms allows us to penalize \"hallucinated\" interactions\n",
    "    all_bins = set(method_histogram.keys()) | set(reference_histogram.keys())\n",
    "    all_bins = sorted(all_bins)  # keep bins in a fixed order for consistency\n",
    "\n",
    "    structured_interaction_bins = [\n",
    "        bin for bin in all_bins if bin.split(\":\")[-1] in (\"HBAcceptor\", \"HBDonor\")\n",
    "    ]\n",
    "    unstructured_interaction_bins = [\n",
    "        bin for bin in all_bins if bin.split(\":\")[-1] in (\"VdWContact\", \"Hydrophobic\")\n",
    "    ]\n",
    "\n",
    "    if not structured_interaction_bins or not unstructured_interaction_bins:\n",
    "        continue\n",
    "\n",
    "    # convert histograms to aligned vectors\n",
    "    structured_method_histogram_vector = np.array(\n",
    "        np.array([method_histogram.get(bin, 0) for bin in structured_interaction_bins])\n",
    "    )\n",
    "    structured_reference_histogram_vector = np.array(\n",
    "        np.array([reference_histogram.get(bin, 0) for bin in structured_interaction_bins])\n",
    "    )\n",
    "\n",
    "    unstructured_method_histogram_vector = np.array(\n",
    "        np.array([method_histogram.get(bin, 0) for bin in unstructured_interaction_bins])\n",
    "    )\n",
    "    unstructured_reference_histogram_vector = np.array(\n",
    "        np.array([reference_histogram.get(bin, 0) for bin in unstructured_interaction_bins])\n",
    "    )\n",
    "\n",
    "    if (\n",
    "        not structured_method_histogram_vector.any()\n",
    "        or not structured_reference_histogram_vector.any()\n",
    "    ):\n",
    "        continue\n",
    "\n",
    "    # compute the EMD values of each method's PLIF histograms\n",
    "    try:\n",
    "        structured_emd = wasserstein_distance(\n",
    "            structured_method_histogram_vector, structured_reference_histogram_vector\n",
    "        )\n",
    "    except Exception as e:\n",
    "        structured_emd = np.nan\n",
    "        print(f\"Skipping structured EMD computation for {method} target {target} due to: {e}\")\n",
    "\n",
    "    try:\n",
    "        unstructured_emd = wasserstein_distance(\n",
    "            unstructured_method_histogram_vector,\n",
    "            unstructured_reference_histogram_vector,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        unstructured_emd = np.nan\n",
    "        print(f\"Skipping unstructured EMD computation for {method} target {target} due to: {e}\")\n",
    "\n",
    "    if structured_emd is np.nan or unstructured_emd is np.nan:\n",
    "        continue\n",
    "\n",
    "    struct_emd_values.append(\n",
    "        {\n",
    "            \"Category\": method,\n",
    "            \"Target\": target,\n",
    "            \"Structured_EMD\": structured_emd,\n",
    "            \"Unstructured_EMD\": unstructured_emd,\n",
    "            \"Method_Histogram\": dict(sorted(method_histogram.items())),\n",
    "            \"Reference_Histogram\": dict(sorted(reference_histogram.items())),\n",
    "        }\n",
    "    )\n",
    "\n",
    "struct_emd_values_df = pd.DataFrame(\n",
    "    struct_emd_values,\n",
    "    columns=[\n",
    "        \"Category\",\n",
    "        \"Target\",\n",
    "        \"Structured_EMD\",\n",
    "        \"Unstructured_EMD\",\n",
    "        \"Method_Histogram\",\n",
    "        \"Reference_Histogram\",\n",
    "    ],\n",
    ")\n",
    "struct_emd_values_df.to_csv(\"casp15_structured_plif_metrics.csv\")\n",
    "\n",
    "# get unique categories\n",
    "categories = struct_emd_values_df[\"Category\"].unique()\n",
    "\n",
    "# define colors and markers for each category\n",
    "colors = plt.cm.get_cmap(\"tab10\", len(categories))\n",
    "markers = [\"o\", \"s\", \"D\", \"^\", \"v\", \"<\", \">\", \"p\", \"*\", \"h\"]\n",
    "\n",
    "# create a scatter plot with lines connecting the paired values for each category\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    category_df = struct_emd_values_df[struct_emd_values_df[\"Category\"] == category]\n",
    "\n",
    "    # perform a paired t-test\n",
    "    t_stat, p_value = ttest_rel(category_df[\"Structured_EMD\"], category_df[\"Unstructured_EMD\"])\n",
    "    print(f\"Category: {category} - T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "    # plot the values\n",
    "    plt.plot(\n",
    "        category_df.index,\n",
    "        category_df[\"Structured_EMD\"],\n",
    "        marker=markers[i % len(markers)],\n",
    "        linestyle=\"-\",\n",
    "        color=colors(i),\n",
    "        label=f\"{category} Structured_EMD\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        category_df.index,\n",
    "        category_df[\"Unstructured_EMD\"],\n",
    "        marker=markers[i % len(markers)],\n",
    "        linestyle=\"--\",\n",
    "        color=colors(i),\n",
    "        label=f\"{category} Unstructured_EMD\",\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"EMD Value\")\n",
    "plt.title(\"Comparison of Structured_EMD and Unstructured_EMD by Method\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig(\"casp15_structured_vs_unstructured_emd_values.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoseBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
