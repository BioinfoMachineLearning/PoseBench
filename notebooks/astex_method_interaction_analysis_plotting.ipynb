{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astex Diverse Method Interaction Analysis Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess  # nosec\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from beartype import beartype\n",
    "from beartype.typing import Any, Literal\n",
    "from Bio.PDB import PDBIO, PDBParser, Select\n",
    "from omegaconf import DictConfig, open_dict\n",
    "from posecheck import PoseCheck\n",
    "from rdkit import Chem\n",
    "from scipy.stats import wasserstein_distance\n",
    "from tqdm import tqdm\n",
    "\n",
    "from posebench import resolve_method_input_csv_path, resolve_method_output_dir\n",
    "from posebench.analysis.inference_analysis import create_mol_table\n",
    "from posebench.utils.data_utils import count_num_residues_in_pdb_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "baseline_methods = [\n",
    "    \"vina_p2rank\",\n",
    "    \"diffdock\",\n",
    "    \"dynamicbind\",\n",
    "    \"neuralplexer\",\n",
    "    \"rfaa\",\n",
    "    \"chai-lab_ss\",\n",
    "    \"chai-lab\",\n",
    "    \"alphafold3_ss\",\n",
    "    \"alphafold3\",\n",
    "]\n",
    "max_num_repeats_per_method = (\n",
    "    1  # NOTE: Here, to simplify the analysis, we only consider the first run of each method\n",
    ")\n",
    "\n",
    "ad_set_dir = os.path.join(\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"astex_diverse_set\",\n",
    ")\n",
    "assert os.path.exists(\n",
    "    ad_set_dir\n",
    "), \"Please download the Astex Diverse set from `https://zenodo.org/records/13858866` before proceeding.\"\n",
    "\n",
    "# Mappings\n",
    "method_mapping = {\n",
    "    \"vina_p2rank\": \"P2Rank-Vina\",\n",
    "    \"diffdock\": \"DiffDock-L\",\n",
    "    \"dynamicbind\": \"DynamicBind\",\n",
    "    \"neuralplexer\": \"NeuralPLexer\",\n",
    "    \"rfaa\": \"RoseTTAFold-AA\",\n",
    "    \"chai-lab_ss\": \"Chai-1-Single-Seq\",\n",
    "    \"chai-lab\": \"Chai-1\",\n",
    "    \"alphafold3_ss\": \"AF3-Single-Seq\",\n",
    "    \"alphafold3\": \"AF3\",\n",
    "}\n",
    "\n",
    "MAX_ASTEX_DIVERSE_ANALYSIS_PROTEIN_SEQUENCE_LENGTH = (\n",
    "    2000  # Only Astex Diverse targets with protein sequences below this threshold can be analyzed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinSelect(Select):\n",
    "    \"\"\"A class to select only protein residues from a PDB file.\"\"\"\n",
    "\n",
    "    def accept_residue(self, residue: Any):\n",
    "        \"\"\"\n",
    "        Only accept residues that are part of a protein (e.g., standard amino acids).\n",
    "\n",
    "        :param residue: The residue to check.\n",
    "        :return: True if the residue is part of a protein, False otherwise.\n",
    "        \"\"\"\n",
    "        return residue.id[0] == \" \"  # NOTE: `HETATM` flag must be a blank for protein residues\n",
    "\n",
    "\n",
    "class LigandSelect(Select):\n",
    "    \"\"\"A class to select only ligand residues from a PDB file.\"\"\"\n",
    "\n",
    "    def accept_residue(self, residue: Any):\n",
    "        \"\"\"\n",
    "        Only accept residues that are part of a ligand.\n",
    "\n",
    "        :param residue: The residue to check.\n",
    "        :return: True if the residue is part of a ligand, False otherwise.\n",
    "        \"\"\"\n",
    "        return residue.id[0] != \" \"  # NOTE: `HETATM` flag must be a filled for ligand residues\n",
    "\n",
    "\n",
    "@beartype\n",
    "def create_temp_pdb_with_only_molecule_type_residues(\n",
    "    input_pdb_filepath: str,\n",
    "    molecule_type: Literal[\"protein\", \"ligand\"],\n",
    "    add_element_types: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a temporary PDB file with only residues of a chosen molecule type.\n",
    "\n",
    "    :param input_pdb_filepath: The input PDB file path.\n",
    "    :param molecule_type: The molecule type to keep (either \"protein\" or \"ligand\").\n",
    "    :param add_element_types: Whether to add element types to the atoms.\n",
    "    :return: The temporary PDB file path.\n",
    "    \"\"\"\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(molecule_type, input_pdb_filepath)\n",
    "\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "\n",
    "    # create a temporary PDB filepdb_name\n",
    "    temp_pdb_filepath = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdb\")\n",
    "    io.save(\n",
    "        temp_pdb_filepath.name, ProteinSelect() if molecule_type == \"protein\" else LigandSelect()\n",
    "    )\n",
    "\n",
    "    if add_element_types:\n",
    "        with open(temp_pdb_filepath.name.replace(\".pdb\", \"_elem.pdb\"), \"w\") as f:\n",
    "            subprocess.run(  # nosec\n",
    "                f\"pdb_element {temp_pdb_filepath.name}\",\n",
    "                shell=True,\n",
    "                check=True,\n",
    "                stdout=f,\n",
    "            )\n",
    "        shutil.move(temp_pdb_filepath.name.replace(\".pdb\", \"_elem.pdb\"), temp_pdb_filepath.name)\n",
    "\n",
    "    return temp_pdb_filepath.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute interaction fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze `Astex Diverse` set interactions as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"astex_diverse_interaction_dataframes.h5\"):\n",
    "    ad_protein_ligand_filepath_pairs = []\n",
    "    for item in os.listdir(ad_set_dir):\n",
    "        ligand_item_path = os.path.join(ad_set_dir, item)\n",
    "        if os.path.isdir(ligand_item_path):\n",
    "            protein_filepath = os.path.join(ligand_item_path, f\"{item}_protein.pdb\")\n",
    "            ligand_filepath = os.path.join(ligand_item_path, f\"{item}_ligand.sdf\")\n",
    "            if os.path.exists(protein_filepath) and os.path.exists(ligand_filepath):\n",
    "                ad_protein_ligand_filepath_pairs.append((protein_filepath, ligand_filepath))\n",
    "\n",
    "    pc = PoseCheck()\n",
    "    ad_protein_ligand_interaction_dfs = []\n",
    "    for protein_filepath, ligand_filepath in tqdm(\n",
    "        ad_protein_ligand_filepath_pairs, desc=\"Processing Astex Diverse set\"\n",
    "    ):\n",
    "        try:\n",
    "            temp_protein_filepath = create_temp_pdb_with_only_molecule_type_residues(\n",
    "                protein_filepath, molecule_type=\"protein\"\n",
    "            )\n",
    "            pc.load_protein_from_pdb(temp_protein_filepath)\n",
    "            pc.load_ligands_from_sdf(ligand_filepath)\n",
    "            ad_protein_ligand_interaction_df = pc.calculate_interactions(n_jobs=1)\n",
    "            ad_protein_ligand_interaction_df[\"target\"] = Path(protein_filepath).stem.split(\n",
    "                \"_protein\"\n",
    "            )[0]\n",
    "            ad_protein_ligand_interaction_dfs.append(ad_protein_ligand_interaction_df)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error processing Astex Diverse target {protein_filepath, ligand_filepath} due to: {e}. Skipping...\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # NOTE: we iteratively save the interaction dataframes to an HDF5 file\n",
    "        with pd.HDFStore(\"astex_diverse_interaction_dataframes.h5\") as store:\n",
    "            for i, df in enumerate(ad_protein_ligand_interaction_dfs):\n",
    "                store.put(f\"df_{i}\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze interactions of each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and cache Astex Diverse interaction statistics for each baseline method\n",
    "config = \"\"  # NOTE: we do not calculate interactions for relaxed predictions currently\n",
    "dataset = \"astex_diverse\"\n",
    "ensemble_ranking_method = \"consensus\"\n",
    "relax_protein = False\n",
    "pocket_only_baseline = False\n",
    "\n",
    "cfg = DictConfig(\n",
    "    {\n",
    "        \"dataset\": dataset,\n",
    "        \"relax_protein\": relax_protein,\n",
    "        \"pocket_only_baseline\": pocket_only_baseline,\n",
    "        \"input_data_dir\": os.path.join(\"..\", \"data\", f\"{dataset}_set\"),\n",
    "        \"posebusters_ccd_ids_filepath\": os.path.join(\"..\", \"data\", \"posebusters_pdb_ccd_ids.txt\"),\n",
    "        \"dockgen_test_ids_filepath\": os.path.join(\"..\", \"data\", \"dockgen_set\", \"split_test.txt\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "for method in copy.deepcopy(baseline_methods):\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        method_title = method_mapping[method]\n",
    "\n",
    "        single_seq_method = \"_ss\" in method\n",
    "        v1_baseline = method == \"diffdockv1\"\n",
    "\n",
    "        vina_binding_site_method = (\n",
    "            method.split(\"_\")[-1] if \"_\" in method and not single_seq_method else \"p2rank\"\n",
    "        )\n",
    "\n",
    "        vina_suffix = (\n",
    "            f\"_{vina_binding_site_method}\" if \"_\" in method and not single_seq_method else \"\"\n",
    "        )\n",
    "        single_seq_suffix = \"_ss\" if single_seq_method else \"\"\n",
    "\n",
    "        method = method.split(\"_\")[0]\n",
    "\n",
    "        if not os.path.exists(\n",
    "            f\"{method}{single_seq_suffix}{vina_suffix}_{dataset}_interaction_dataframes_{repeat_index}.h5\"\n",
    "        ):\n",
    "            with open_dict(cfg):\n",
    "                cfg.method = method\n",
    "                cfg.repeat_index = repeat_index\n",
    "                cfg.input_csv_path = str(\n",
    "                    \"..\"\n",
    "                    / Path(resolve_method_input_csv_path(method, dataset, pocket_only_baseline))\n",
    "                )\n",
    "                cfg.output_dir = str(\n",
    "                    \"..\"\n",
    "                    / Path(\n",
    "                        resolve_method_output_dir(\n",
    "                            method,\n",
    "                            dataset,\n",
    "                            vina_binding_site_method,\n",
    "                            ensemble_ranking_method,\n",
    "                            repeat_index,\n",
    "                            pocket_only_baseline,\n",
    "                            v1_baseline,\n",
    "                            single_seq_baseline=single_seq_method,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            output_dir = cfg.output_dir + config\n",
    "            if method == \"dynamicbind\":\n",
    "                output_dir = os.path.join(\n",
    "                    Path(output_dir).parent,\n",
    "                    Path(output_dir).stem.replace(f\"_{repeat_index}\", \"\"),\n",
    "                )\n",
    "\n",
    "            mol_table = create_mol_table(\n",
    "                Path(cfg.input_csv_path),\n",
    "                Path(cfg.input_data_dir),\n",
    "                Path(output_dir),\n",
    "                cfg,\n",
    "                relaxed=\"relaxed\" in config,\n",
    "                add_pdb_ids=True,\n",
    "            )\n",
    "\n",
    "            pc = PoseCheck()\n",
    "            astex_protein_ligand_interaction_dfs = []\n",
    "            for row in tqdm(\n",
    "                mol_table.itertuples(index=False),\n",
    "                desc=f\"Processing interactions for {method_title}\",\n",
    "            ):\n",
    "                try:\n",
    "                    protein_filepath, ligand_filepath = str(row.mol_cond), str(row.mol_pred)\n",
    "                    num_residues_in_target_protein = count_num_residues_in_pdb_file(\n",
    "                        protein_filepath\n",
    "                    )\n",
    "                    if (\n",
    "                        num_residues_in_target_protein\n",
    "                        > MAX_ASTEX_DIVERSE_ANALYSIS_PROTEIN_SEQUENCE_LENGTH\n",
    "                    ):\n",
    "                        print(\n",
    "                            f\"{method_title} target {row} has too many protein residues ({num_residues_in_target_protein} > {MAX_ASTEX_DIVERSE_ANALYSIS_PROTEIN_SEQUENCE_LENGTH}) for `MDAnalysis` to fit into CPU memory. Skipping...\"\n",
    "                        )\n",
    "                        continue\n",
    "                    ligand_mol = Chem.MolFromMolFile(ligand_filepath)\n",
    "                    pc.load_protein_from_pdb(protein_filepath)\n",
    "                    pc.load_ligands_from_mols(\n",
    "                        Chem.GetMolFrags(ligand_mol, asMols=True, sanitizeFrags=False)\n",
    "                    )\n",
    "                    protein_ligand_interaction_df = pc.calculate_interactions(n_jobs=1)\n",
    "                    protein_ligand_interaction_df[\"target\"] = row.pdb_id\n",
    "                    astex_protein_ligand_interaction_dfs.append(protein_ligand_interaction_df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {method_title} target {row} due to: {e}. Skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # NOTE: we iteratively save the interaction dataframes to an HDF5 file\n",
    "                with pd.HDFStore(\n",
    "                    f\"{method}{single_seq_suffix}{vina_suffix}_{dataset}_interaction_dataframes_{repeat_index}.h5\"\n",
    "                ) as store:\n",
    "                    for i, df in enumerate(astex_protein_ligand_interaction_dfs):\n",
    "                        store.put(f\"df_{i}\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot interaction statistics for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "\n",
    "# define a function to process each method\n",
    "def process_method(file_path, category):\n",
    "    interactions = []\n",
    "    with pd.HDFStore(file_path) as store:\n",
    "        for key in store.keys():\n",
    "            for row_index in range(len(store[key])):\n",
    "                interaction_types = [\n",
    "                    interaction[2]\n",
    "                    for interaction in store[key].iloc[row_index].keys().tolist()\n",
    "                    if interaction[2]  # NOTE: this excludes the `target` column's singular value\n",
    "                ]\n",
    "                num_hb_acceptors = interaction_types.count(\"HBAcceptor\")\n",
    "                num_hb_donors = interaction_types.count(\"HBDonor\")\n",
    "                num_vdw_contacts = interaction_types.count(\"VdWContact\")\n",
    "                num_hydrophobic = interaction_types.count(\"Hydrophobic\")\n",
    "                interactions.append(\n",
    "                    {\n",
    "                        \"Hydrogen Bond Acceptors\": num_hb_acceptors,\n",
    "                        \"Hydrogen Bond Donors\": num_hb_donors,\n",
    "                        \"Van der Waals Contacts\": num_vdw_contacts,\n",
    "                        \"Hydrophobic Interactions\": num_hydrophobic,\n",
    "                    }\n",
    "                )\n",
    "    df_rows = []\n",
    "    for interaction in interactions:\n",
    "        for interaction_type, num_interactions in interaction.items():\n",
    "            df_rows.append(\n",
    "                {\n",
    "                    \"Category\": category,\n",
    "                    \"InteractionType\": interaction_type,\n",
    "                    \"NumInteractions\": num_interactions,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(df_rows)\n",
    "\n",
    "\n",
    "# load data from files\n",
    "for method in baseline_methods:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        method_title = method_mapping[method]\n",
    "        file_path = f\"{method}_astex_diverse_interaction_dataframes_{repeat_index}.h5\"\n",
    "        if os.path.exists(file_path):\n",
    "            dfs.append(process_method(file_path, method_title))\n",
    "\n",
    "if os.path.exists(\"astex_diverse_interaction_dataframes.h5\"):\n",
    "    dfs.append(process_method(\"astex_diverse_interaction_dataframes.h5\", \"Reference\"))\n",
    "\n",
    "# combine statistics\n",
    "assert len(dfs) > 0, \"No interaction dataframes found.\"\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# define font properties\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "\n",
    "# plot statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(34, 14), sharey=False)\n",
    "\n",
    "interaction_types = [\n",
    "    \"Hydrogen Bond Acceptors\",\n",
    "    \"Hydrogen Bond Donors\",\n",
    "    \"Van der Waals Contacts\",\n",
    "    \"Hydrophobic Interactions\",\n",
    "]\n",
    "plot_types = [\"box\", \"box\", \"violin\", \"violin\"]\n",
    "\n",
    "for ax, interaction, plot_type in zip(axes.flatten(), interaction_types, plot_types):\n",
    "    data = df[df[\"InteractionType\"] == interaction]\n",
    "\n",
    "    if plot_type == \"box\":\n",
    "        sns.boxplot(data=data, x=\"Category\", y=\"NumInteractions\", ax=ax, showfliers=True)\n",
    "        sns.stripplot(\n",
    "            data=data,\n",
    "            x=\"Category\",\n",
    "            y=\"NumInteractions\",\n",
    "            ax=ax,\n",
    "            color=\"black\",\n",
    "            alpha=0.3,\n",
    "            jitter=True,\n",
    "        )\n",
    "    elif plot_type == \"violin\":\n",
    "        sns.violinplot(data=data, x=\"Category\", y=\"NumInteractions\", ax=ax)\n",
    "        sns.stripplot(\n",
    "            data=data,\n",
    "            x=\"Category\",\n",
    "            y=\"NumInteractions\",\n",
    "            ax=ax,\n",
    "            color=\"black\",\n",
    "            alpha=0.3,\n",
    "            jitter=True,\n",
    "        )\n",
    "\n",
    "    ax.set_title(interaction)\n",
    "    ax.set_ylabel(\"No. Interactions\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"astex_diverse_method_interaction_analysis.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot interaction metrics for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "\n",
    "# define helper functions\n",
    "def split_string_at_numeric(s: str) -> list:\n",
    "    \"\"\"Split a string at numeric characters.\"\"\"\n",
    "    return re.split(r\"\\d+\", s)\n",
    "\n",
    "\n",
    "def bin_interactions(file_path, category):\n",
    "    \"\"\"Bin interactions for each target.\"\"\"\n",
    "    interactions = defaultdict(list)\n",
    "    with pd.HDFStore(file_path) as store:\n",
    "        for key in store.keys():\n",
    "            for row_index in range(len(store[key])):\n",
    "                target = store[key].iloc[row_index][\"target\"]\n",
    "                if not isinstance(target, str):\n",
    "                    target = target.values[0]\n",
    "\n",
    "                try:\n",
    "                    interactions[target].extend(\n",
    "                        [\n",
    "                            f\"{split_string_at_numeric(row[0])[0]}:{split_string_at_numeric(row[1])[0]}:{row[2]}\"\n",
    "                            for row in store[key].iloc[row_index].index.values[:-1]\n",
    "                        ]\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Error processing {key} row {row_index} for target {target} due to: {e}. Skipping...\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "    df_rows = []\n",
    "    for target in interactions:\n",
    "        target_interactions = interactions[target]\n",
    "        target_interactions_histogram = defaultdict(int)\n",
    "        for target_interaction in target_interactions:\n",
    "            target_interactions_histogram[target_interaction] += 1\n",
    "\n",
    "        df_rows.append(\n",
    "            {\n",
    "                \"Category\": category,\n",
    "                \"Target\": target,\n",
    "                \"Interactions_Histogram\": target_interactions_histogram,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(df_rows)\n",
    "\n",
    "\n",
    "def histogram_to_vector(histogram, bins):\n",
    "    \"\"\"Convert a histogram dictionary to a vector aligned with bins.\"\"\"\n",
    "    return np.array([histogram.get(bin, 0) for bin in bins])\n",
    "\n",
    "\n",
    "# load data from files\n",
    "for method in baseline_methods:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        method_title = method_mapping[method]\n",
    "        file_path = f\"{method}_astex_diverse_interaction_dataframes_{repeat_index}.h5\"\n",
    "        if os.path.exists(file_path):\n",
    "            dfs.append(bin_interactions(file_path, method_title))\n",
    "\n",
    "assert os.path.exists(\n",
    "    \"astex_diverse_interaction_dataframes.h5\"\n",
    "), \"No reference interaction dataframe found.\"\n",
    "reference_df = bin_interactions(\"astex_diverse_interaction_dataframes.h5\", \"Reference\")\n",
    "\n",
    "# combine bins from all method dataframes\n",
    "assert len(dfs) > 0, \"No interaction dataframes found.\"\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "emd_values = []\n",
    "for method in df[\"Category\"].unique():\n",
    "    for target in reference_df[\"Target\"]:\n",
    "        # step 1: extract unique bins for each pair of method and reference histograms\n",
    "        method_histogram = df[(df[\"Category\"] == method) & (df[\"Target\"] == target)][\n",
    "            \"Interactions_Histogram\"\n",
    "        ]\n",
    "        reference_histogram = reference_df[reference_df[\"Target\"] == target][\n",
    "            \"Interactions_Histogram\"\n",
    "        ]\n",
    "        if method_histogram.empty:\n",
    "            # NOTE: if a method does not have any ProLIF-parseable interactions\n",
    "            # for a target, we skip-penalize it with a null EMD value\n",
    "            emd_values.append({\"Category\": method, \"Target\": target, \"EMD\": np.nan})\n",
    "            continue\n",
    "        if reference_histogram.empty:\n",
    "            # NOTE: if a target does not have any ProLIF-parseable interactions\n",
    "            # in the reference data, we skip this target\n",
    "            print(\n",
    "                f\"Skipping target {target} for method {method} due to missing reference interaction data.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # NOTE: collecting bins from both histograms allows us to penalize \"hallucinated\" interactions\n",
    "        all_bins = set(method_histogram.values[0].keys()) | set(\n",
    "            reference_histogram.values[0].keys()\n",
    "        )\n",
    "        all_bins = sorted(all_bins)  # keep bins in a fixed order for consistency\n",
    "\n",
    "        # step 2: convert histograms to aligned vectors\n",
    "        method_histogram_vector = method_histogram.apply(\n",
    "            lambda h: histogram_to_vector(h, all_bins)\n",
    "        ).squeeze()\n",
    "        reference_histogram_vector = reference_histogram.apply(\n",
    "            lambda h: histogram_to_vector(h, all_bins)\n",
    "        ).squeeze()\n",
    "\n",
    "        # step 3: compute the EMD values of each method's PLIF histograms\n",
    "        try:\n",
    "            emd = wasserstein_distance(method_histogram_vector, reference_histogram_vector)\n",
    "        except Exception as e:\n",
    "            emd = np.nan\n",
    "            print(f\"Skipping EMD computation for {method} target {target} due to: {e}\")\n",
    "\n",
    "        emd_values.append(\n",
    "            {\n",
    "                \"Category\": method,\n",
    "                \"Target\": target,\n",
    "                \"EMD\": emd,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# plot the EMD and WM values for each method\n",
    "all_emd_values = [\n",
    "    min(10.0, entry[\"EMD\"]) for entry in emd_values\n",
    "]  # clip EMD values to 10.0 when constructing WM values\n",
    "min_emd = np.nanmin(all_emd_values)\n",
    "max_emd = np.nanmax(all_emd_values)\n",
    "for entry in emd_values:\n",
    "    # NOTE: we normalize the EMD values to the range `[0, 1]`\n",
    "    # to compute the Wasserstein Matching (WM) metric while\n",
    "    # ensuring missing predictions are maximally skip-penalized\n",
    "    emd = max_emd if np.isnan(entry[\"EMD\"]).item() else entry[\"EMD\"]\n",
    "    normalized_score = 1 - (emd - min_emd) / (max_emd - min_emd)\n",
    "    entry[\"WM\"] = normalized_score\n",
    "\n",
    "emd_values_df = pd.DataFrame(emd_values, columns=[\"Category\", \"Target\", \"EMD\", \"WM\"])\n",
    "emd_values_df.to_csv(\"astex_diverse_plif_metrics.csv\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=emd_values_df, x=\"Category\", y=\"EMD\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"PLIF-EMD\")\n",
    "plt.savefig(\"astex_diverse_plif_emd_values.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=emd_values_df, x=\"Category\", y=\"WM\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"PLIF-WM\")\n",
    "plt.savefig(\"astex_diverse_plif_wm_values.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoseBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
