{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Modes Analysis Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypdb\n",
    "import seaborn as sns\n",
    "\n",
    "from posebench.analysis.inference_analysis import BUST_TEST_COLUMNS\n",
    "from posebench.utils.data_utils import parse_fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install MMseqs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mamba install -c bioconda mmseqs2=17.b804f=hd6d6fdc_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "baseline_methods = [\n",
    "    \"vina_p2rank\",\n",
    "    \"diffdock\",\n",
    "    \"dynamicbind\",\n",
    "    \"neuralplexer\",\n",
    "    \"rfaa\",\n",
    "    \"chai-lab_ss\",\n",
    "    \"chai-lab\",\n",
    "    \"boltz_ss\",\n",
    "    \"boltz\",\n",
    "    \"alphafold3_ss\",\n",
    "    \"alphafold3\",\n",
    "]\n",
    "max_num_repeats_per_method = 3\n",
    "method_max_training_cutoff_date = \"2021-09-30\"\n",
    "\n",
    "datasets = [\"astex_diverse\", \"posebusters_benchmark\", \"dockgen\", \"casp15\"]\n",
    "\n",
    "# PoseBusters Benchmark deposition dates\n",
    "pb_deposition_dates_filepath = \"posebusters_benchmark_complex_pdb_deposition_dates.csv\"\n",
    "assert os.path.exists(\n",
    "    pb_deposition_dates_filepath\n",
    "), \"Please prepare the PoseBusters Benchmark complex PDB deposition dates CSV file via later steps in `failure_modes_analysis_plotting.ipynb` before proceeding.\"\n",
    "\n",
    "pb_pdb_id_deposition_date_mapping_df = pd.read_csv(pb_deposition_dates_filepath)\n",
    "pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"]\n",
    ")\n",
    "pb_pdb_id_deposition_date_mapping_df = pb_pdb_id_deposition_date_mapping_df[\n",
    "    pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"] > method_max_training_cutoff_date\n",
    "]\n",
    "pb_pdb_id_deposition_date_mapping = dict(\n",
    "    zip(\n",
    "        pb_pdb_id_deposition_date_mapping_df[\"PDB ID\"],\n",
    "        pb_pdb_id_deposition_date_mapping_df[\"Deposition Date\"].astype(str),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Filepaths for each baseline method\n",
    "globals()[\"vina_output_dir\"] = os.path.join(\"..\", \"forks\", \"Vina\", \"inference\")\n",
    "globals()[\"diffdock_output_dir\"] = os.path.join(\"..\", \"forks\", \"DiffDock\", \"inference\")\n",
    "globals()[\"dynamicbind_output_dir\"] = os.path.join(\n",
    "    \"..\", \"forks\", \"DynamicBind\", \"inference\", \"outputs\", \"results\"\n",
    ")\n",
    "globals()[\"neuralplexer_output_dir\"] = os.path.join(\"..\", \"forks\", \"NeuralPLexer\", \"inference\")\n",
    "globals()[\"rfaa_output_dir\"] = os.path.join(\"..\", \"forks\", \"RoseTTAFold-All-Atom\", \"inference\")\n",
    "globals()[\"chai-lab_output_dir\"] = os.path.join(\"..\", \"forks\", \"chai-lab\", \"inference\")\n",
    "globals()[\"boltz_output_dir\"] = os.path.join(\"..\", \"forks\", \"boltz\", \"inference\")\n",
    "globals()[\"alphafold3_output_dir\"] = os.path.join(\"..\", \"forks\", \"alphafold3\", \"inference\")\n",
    "globals()[\"casp15_output_dir\"] = os.path.join(\"..\", \"data\", \"test_cases\", \"casp15\")\n",
    "for config in [\"\", \"_relaxed\"]:\n",
    "    for dataset in datasets:\n",
    "        for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "            # P2Rank-Vina results\n",
    "            globals()[\n",
    "                f\"vina_p2rank_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"vina_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_vina_p2rank_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"vina_p2rank_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # DiffDock results\n",
    "            globals()[f\"diffdock_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"diffdock_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_diffdock_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"diffdock_{dataset}_output_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # DynamicBind results\n",
    "            globals()[\n",
    "                f\"dynamicbind_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"dynamicbind_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_dynamicbind_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"{dataset}_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # NeuralPLexer results\n",
    "            globals()[\n",
    "                f\"neuralplexer_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"neuralplexer_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_neuralplexer_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"neuralplexer_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # RoseTTAFold-All-Atom results\n",
    "            globals()[f\"rfaa_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"rfaa_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_rfaa_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"rfaa_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Chai-1 (Single-Seq) results\n",
    "            globals()[\n",
    "                f\"chai-lab_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"chai-lab_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_chai-lab_ss_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"chai-lab_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # Chai-1 results\n",
    "            globals()[f\"chai-lab_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"chai-lab_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_chai-lab_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"chai-lab_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Boltz (Single-Seq) results\n",
    "            globals()[f\"boltz_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"boltz_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_boltz_ss_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"boltz_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Boltz results\n",
    "            globals()[f\"boltz_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"boltz_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_boltz_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"boltz_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # AlphaFold 3 (Single-Seq) results\n",
    "            globals()[\n",
    "                f\"alphafold3_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"alphafold3_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_alphafold3_ss_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"alphafold3_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # AlphaFold 3 results\n",
    "            globals()[f\"alphafold3_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"alphafold3_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_alphafold3_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"alphafold3_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Mappings\n",
    "method_mapping = {\n",
    "    \"vina_p2rank\": \"P2Rank-Vina\",\n",
    "    \"diffdock\": \"DiffDock-L\",\n",
    "    \"dynamicbind\": \"DynamicBind\",\n",
    "    \"neuralplexer\": \"NeuralPLexer\",\n",
    "    \"rfaa\": \"RFAA\",\n",
    "    \"chai-lab_ss\": \"Chai-1-Single-Seq\",\n",
    "    \"chai-lab\": \"Chai-1\",\n",
    "    \"boltz_ss\": \"Boltz-1-Single-Seq\",\n",
    "    \"boltz\": \"Boltz-1\",\n",
    "    \"alphafold3_ss\": \"AF3-Single-Seq\",\n",
    "    \"alphafold3\": \"AF3\",\n",
    "}\n",
    "\n",
    "method_category_mapping = {\n",
    "    \"vina_p2rank\": \"Conventional blind\",\n",
    "    \"diffdock\": \"DL-based blind\",\n",
    "    \"dynamicbind\": \"DL-based blind\",\n",
    "    \"neuralplexer\": \"DL-based blind\",\n",
    "    \"rfaa\": \"DL-based blind\",\n",
    "    \"chai-lab_ss\": \"DL-based blind\",\n",
    "    \"chai-lab\": \"DL-based blind\",\n",
    "    \"boltz_ss\": \"DL-based blind\",\n",
    "    \"boltz\": \"DL-based blind\",\n",
    "    \"alphafold3_ss\": \"DL-based blind\",\n",
    "    \"alphafold3\": \"DL-based blind\",\n",
    "}\n",
    "\n",
    "dataset_mapping = {\n",
    "    \"astex_diverse\": \"Astex Diverse set\",\n",
    "    \"posebusters_benchmark\": \"Posebusters Benchmark set\",\n",
    "    \"dockgen\": \"DockGen set\",\n",
    "    \"casp15\": \"CASP15 set\",\n",
    "}\n",
    "\n",
    "casp15_target_pdb_id_mapping = {\n",
    "    # NOTE: `?` indicates that the target's crystal structure is not publicly available\n",
    "    \"H1135\": \"7z8y\",\n",
    "    \"H1171v1\": \"7pbl\",\n",
    "    \"H1171v2\": \"7pbl\",\n",
    "    \"H1172v1\": \"7pbp\",\n",
    "    \"H1172v2\": \"7pbp\",\n",
    "    \"H1172v3\": \"7pbp\",\n",
    "    \"H1172v4\": \"7pbp\",\n",
    "    \"T1124\": \"7ux8\",\n",
    "    \"T1127v2\": \"?\",\n",
    "    \"T1146\": \"?\",\n",
    "    \"T1152\": \"7r1l\",\n",
    "    \"T1158v1\": \"8sx8\",\n",
    "    \"T1158v2\": \"8sxb\",\n",
    "    \"T1158v3\": \"8sx7\",\n",
    "    \"T1158v4\": \"8swn\",\n",
    "    \"T1170\": \"7pbr\",\n",
    "    \"T1181\": \"?\",\n",
    "    \"T1186\": \"?\",\n",
    "    \"T1187\": \"8ad2\",\n",
    "    \"T1188\": \"8c6z\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test results for each baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and report test results for each baseline method\n",
    "for config in [\"\"]:\n",
    "    for dataset in datasets:\n",
    "        for method in baseline_methods:\n",
    "            for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "                method_title = method_mapping[method]\n",
    "\n",
    "                if not os.path.exists(\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "                    ]\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"] = (\n",
    "                    pd.read_csv(\n",
    "                        globals()[\n",
    "                            f\"{method}_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if dataset == \"casp15\":\n",
    "                    # count the number of ligands in each target complex, and assign these corresponding numbers to the ligands (rows) of each complex\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"num_target_ligands\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "                        .groupby([\"target\", \"mdl\"])[\"pose\"]\n",
    "                        .transform(\"count\")\n",
    "                    )\n",
    "\n",
    "                    # filter out non-relevant ligand predictions, and for all methods select only their first model for each ligand\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        np.where(\n",
    "                            (\n",
    "                                globals()[\n",
    "                                    f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                                ].relevant\n",
    "                            ),\n",
    "                            True,\n",
    "                            False,\n",
    "                        )\n",
    "                        & (\n",
    "                            globals()[\n",
    "                                f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                            ].mdl\n",
    "                            == 1\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                    # finalize bust (i.e., scoring) results for CASP15, using dummy values for `pb_valid` and `crmsd_≤_1å`\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"rmsd_≤_2å\"\n",
    "                    ] = (\n",
    "                        globals()[\n",
    "                            f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                        ].loc[:, \"rmsd\"]\n",
    "                        <= 2\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pdb_valid\"\n",
    "                    ] = True\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"crmsd_≤_1å\"\n",
    "                    ] = True\n",
    "\n",
    "                else:\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        BUST_TEST_COLUMNS + [\"rmsd\", \"centroid_distance\", \"mol_id\"]\n",
    "                    ]\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pb_valid\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "                        .iloc[:, 1:-3]\n",
    "                        .all(axis=1)\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"crmsd_≤_1å\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                            \"centroid_distance\"\n",
    "                        ]\n",
    "                        < 1\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pdb_id\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        \"mol_id\"\n",
    "                    ]\n",
    "\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"method\"\n",
    "                ] = method\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"post-processing\"\n",
    "                ] = (\"energy minimization\" if config == \"_relaxed\" else \"none\")\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"dataset\"\n",
    "                ] = dataset\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"docked_ligand_successfully_loaded\"\n",
    "                ] = (\n",
    "                    True\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ][[\"mol_pred_loaded\", \"mol_true_loaded\", \"mol_cond_loaded\"]].all(axis=1)\n",
    "                )\n",
    "\n",
    "                if dataset == \"posebusters_benchmark\":\n",
    "                    # keep only the results for complexes deposited in the PDB after the maximum cutoff date for any method's training data\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        \"pdb_id\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        \"mol_id\"\n",
    "                    ].map(\n",
    "                        lambda x: x.lower().split(\"_\")[0]\n",
    "                    )\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                            \"pdb_id\"\n",
    "                        ].isin(pb_pdb_id_deposition_date_mapping.keys())\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_method_index(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Assign method index for plotting.\n",
    "\n",
    "    :param method: Method name.\n",
    "    :return: Method index.\n",
    "    \"\"\"\n",
    "    return list(method_mapping.keys()).index(method)\n",
    "\n",
    "\n",
    "def categorize_method(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Categorize method for plotting.\n",
    "\n",
    "    :param method: Method name.\n",
    "    :return: Method category.\n",
    "    \"\"\"\n",
    "    return method_category_mapping.get(method, \"Misc\")\n",
    "\n",
    "\n",
    "def subset_counter(\n",
    "    subset_counter: Counter, superset_counter: Counter, normalize_subset: bool = False\n",
    ") -> Counter:\n",
    "    \"\"\"\n",
    "    Subset a superset counter by a subset counter.\n",
    "\n",
    "    :param subset_counter: Subset counter.\n",
    "    :param superset_counter: Superset counter.\n",
    "    :param normalize_subset: Normalize subset counter by superset counter.\n",
    "    :return: Subsetted counter.\n",
    "    \"\"\"\n",
    "    subsetted_counter = Counter()\n",
    "    for key in subset_counter:\n",
    "        if key in superset_counter and superset_counter[key] != 0:\n",
    "            subsetted_counter[key] = (\n",
    "                subset_counter[key] / superset_counter[key]\n",
    "                if normalize_subset\n",
    "                else superset_counter[key]\n",
    "            )\n",
    "        else:\n",
    "            subsetted_counter[key] = 0  # or handle as needed\n",
    "    return subsetted_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and organize the results CSVs\n",
    "for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "    globals()[f\"results_table_{repeat_index}\"] = pd.concat(\n",
    "        [\n",
    "            globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "            for dataset in datasets\n",
    "            for method in baseline_methods\n",
    "            for config in [\"\"]\n",
    "            if f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\" in globals()\n",
    "        ]\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method_category\"] = globals()[\n",
    "        f\"results_table_{repeat_index}\"\n",
    "    ][\"method\"].apply(categorize_method)\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method_assignment_index\"] = globals()[\n",
    "        f\"results_table_{repeat_index}\"\n",
    "    ][\"method\"].apply(assign_method_index)\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"crmsd_within_threshold\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"crmsd_≤_1å\"].fillna(False)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_≤_2å\"].fillna(False)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold_and_pb_valid\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold\"]\n",
    "    ) & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"pb_valid\"].fillna(False))\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"RMSD ≤ 2 Å & PB-Valid\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"rmsd_within_threshold_and_pb_valid\"]\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"cRMSD ≤ 1 Å\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"crmsd_within_threshold\"]\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"RMSD ≤ 2 Å\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"rmsd_within_threshold\"]\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"].map(dataset_mapping)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"].map(method_mapping)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect metadata across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PDB IDs of complexes across all datasets\n",
    "for dataset in datasets:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "            == dataset_mapping[dataset]\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[:, \"pdb_id\"].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of complex types across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of the complexes across all datasets\n",
    "pdb_info_cache = dict()\n",
    "\n",
    "for repeat_index in [1]:  # NOTE: we only consider the first repeat\n",
    "    all_complexes_df = []\n",
    "    for dataset in datasets:\n",
    "        complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_{repeat_index}\"], columns=[\"pdb_id\"]\n",
    "        )\n",
    "        complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        all_complexes_df.append(complexes_df)\n",
    "    all_complexes_df = pd.concat(all_complexes_df, ignore_index=True)\n",
    "\n",
    "    if all_complexes_df.empty:\n",
    "        print(\"No complexes for any dataset.\")\n",
    "        continue\n",
    "\n",
    "    complex_function_annotations = []\n",
    "    for pdb_id in set(all_complexes_df[\"pdb_id\"]):\n",
    "        pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "        if pdb_id == \"?\":\n",
    "            continue\n",
    "        if pdb_id in pdb_info_cache:\n",
    "            pdb_id_info = pdb_info_cache[pdb_id]\n",
    "        else:\n",
    "            pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "            pdb_info_cache[pdb_id] = pdb_id_info\n",
    "        if not pdb_id_info:\n",
    "            continue\n",
    "        complex_function_annotations.append(\n",
    "            # NOTE: these represent functional keywords\n",
    "            pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "\n",
    "    complex_function_annotation_counts = Counter(complex_function_annotations)\n",
    "    df = pd.DataFrame(\n",
    "        complex_function_annotation_counts.items(),\n",
    "        columns=[\"Keyword\", \"Frequency\"],\n",
    "    )\n",
    "    df[\"Frequency\"] = df[\"Frequency\"].astype(int)\n",
    "    df = df.sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.barplot(data=df, x=\"Frequency\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "    max_freq = df[\"Frequency\"].max()\n",
    "    plt.xticks(ticks=range(0, max_freq + 1), labels=range(0, max_freq + 1), rotation=60)\n",
    "\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Complex Annotation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"complexes_functional_keywords_{repeat_index}.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"{len(complex_function_annotations)} complex annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of the PoseBusters Benchmark dataset's complex deposition dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # report the PDB deposition date of each PoseBusters Benchmark complex\n",
    "# posebusters_complex_deposition_dates = dict()\n",
    "# for pdb_id in set(\n",
    "#     all_complexes_df[all_complexes_df[\"dataset\"] == \"Posebusters Benchmark set\"][\"pdb_id\"]\n",
    "# ):\n",
    "#     pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "#     if pdb_id == \"?\":\n",
    "#         continue\n",
    "#     if pdb_id in pdb_info_cache:\n",
    "#         pdb_id_info = pdb_info_cache[pdb_id]\n",
    "#     else:\n",
    "#         pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "#         pdb_info_cache[pdb_id] = pdb_id_info\n",
    "#     if not pdb_id_info:\n",
    "#         continue\n",
    "#     posebusters_complex_deposition_dates[pdb_id] = pdb_id_info[\"rcsb_accession_info\"][\n",
    "#         \"deposit_date\"\n",
    "#     ]\n",
    "\n",
    "# # analyze and plot statistics of the PoseBusters complexes' deposition dates\n",
    "# posebusters_complex_pdb_deposition_dates_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"PDB ID\": posebusters_complex_deposition_dates.keys(),\n",
    "#         \"Deposition Date\": posebusters_complex_deposition_dates.values(),\n",
    "#     }\n",
    "# )\n",
    "# posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "#     posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    "# )\n",
    "# posebusters_complex_pdb_deposition_dates_df.to_csv(\n",
    "#     \"posebusters_benchmark_complex_pdb_deposition_dates.csv\", index=False\n",
    "# )\n",
    "\n",
    "# posebusters_pre_cutoff_complexes = posebusters_complex_pdb_deposition_dates_df[\n",
    "#     posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    "#     <= method_max_training_cutoff_date\n",
    "# ]\n",
    "# posebusters_post_cutoff_complexes = posebusters_complex_pdb_deposition_dates_df[\n",
    "#     posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    "#     > method_max_training_cutoff_date\n",
    "# ]\n",
    "# print(\n",
    "#     f\"{len(posebusters_pre_cutoff_complexes)}/{len(posebusters_complex_pdb_deposition_dates_df)} PoseBusters Benchmark complexes deposited before maximum cutoff of {method_max_training_cutoff_date}.\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"{len(posebusters_post_cutoff_complexes)}/{len(posebusters_complex_pdb_deposition_dates_df)} PoseBusters Benchmark complexes deposited after maximum cutoff of {method_max_training_cutoff_date}.\"\n",
    "# )\n",
    "\n",
    "# sns.histplot(posebusters_complex_pdb_deposition_dates_df[\"Deposition Date\"].values, bins=25)\n",
    "# plt.xlabel(\"Deposition Date\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"posebusters_benchmark_complex_pdb_deposition_dates.png\")\n",
    "# plt.show()\n",
    "# plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify failure modes across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PDB IDs of complexes for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by any method\n",
    "for dataset in datasets:\n",
    "    docking_success_column = \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "            == dataset_mapping[dataset]\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_docked_by_any_method_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"{dataset}_complexes_not_docked_by_any_method_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"pdb_id\"].isin(\n",
    "                    globals()[f\"{dataset}_complexes_docked_by_any_method_{repeat_index}\"]\n",
    "                ),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find commonalities among the failure modes of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of the failed complexes across all datasets\n",
    "for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "    all_failed_complexes_df = []\n",
    "    for dataset in datasets:\n",
    "        failed_complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_not_docked_by_any_method_{repeat_index}\"],\n",
    "            columns=[\"pdb_id\"],\n",
    "        )\n",
    "        failed_complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        all_failed_complexes_df.append(failed_complexes_df)\n",
    "    all_failed_complexes_df = pd.concat(all_failed_complexes_df, ignore_index=True)\n",
    "\n",
    "    if all_failed_complexes_df.empty:\n",
    "        print(\"No failed complexes for any dataset.\")\n",
    "        continue\n",
    "\n",
    "    failed_complex_function_annotations = []\n",
    "    for pdb_id in set(all_failed_complexes_df[\"pdb_id\"]):\n",
    "        pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "        if pdb_id == \"?\":\n",
    "            continue\n",
    "        if pdb_id in pdb_info_cache:\n",
    "            pdb_id_info = pdb_info_cache[pdb_id]\n",
    "        else:\n",
    "            pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "            pdb_info_cache[pdb_id] = pdb_id_info\n",
    "        if not pdb_id_info:\n",
    "            continue\n",
    "        failed_complex_function_annotations.append(\n",
    "            # NOTE: these represent functional keywords\n",
    "            pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "\n",
    "    failed_complex_function_annotation_counts = subset_counter(\n",
    "        Counter(failed_complex_function_annotations),\n",
    "        complex_function_annotation_counts,\n",
    "        normalize_subset=True,\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        failed_complex_function_annotation_counts.items(),\n",
    "        columns=[\"Keyword\", \"Failed Ratio\"],\n",
    "    )\n",
    "    df[\"Frequency\"] = df[\"Keyword\"].map(complex_function_annotation_counts)\n",
    "    df.sort_values(\n",
    "        by=[\"Failed Ratio\", \"Frequency\"], ascending=False, inplace=True, ignore_index=True\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df, x=\"Failed Ratio\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "    plt.xlabel(\"Failed Ratio\")\n",
    "    plt.ylabel(\"Complex Annotation\")\n",
    "\n",
    "    plt.xlim(0, 1.1)\n",
    "\n",
    "    # annotate bars with the frequency of each keyword\n",
    "    for index, row in df.iterrows():\n",
    "        plt.text(\n",
    "            x=row[\"Failed Ratio\"] + 0.01,\n",
    "            y=index,\n",
    "            s=f\"{row['Failed Ratio']:.2f} ({row['Frequency']})\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"failed_complexes_functional_keywords_{repeat_index}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"{len(failed_complex_function_annotations)} complex annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify AlphaFold 3's failure modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find complexes that AlphaFold 3 failed to correctly predict\n",
    "for dataset in datasets:\n",
    "    docking_success_column = \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            (\n",
    "                globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "                == dataset_mapping[dataset]\n",
    "            )\n",
    "            & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] == \"AF3\")\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"{dataset}_complexes_not_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"pdb_id\"].isin(\n",
    "                    globals()[f\"{dataset}_complexes_docked_by_af3_{repeat_index}\"]\n",
    "                ),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record and plot AlphaFold 3's failure mode metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of AlphaFold 3's failed complexes across all datasets\n",
    "all_failed_af3_complexes_df = []\n",
    "for dataset in datasets:\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        failed_af3_complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_not_docked_by_af3_{repeat_index}\"],\n",
    "            columns=[\"pdb_id\"],\n",
    "        )\n",
    "        failed_af3_complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        failed_af3_complexes_df[\"repeat_index\"] = repeat_index\n",
    "        all_failed_af3_complexes_df.append(failed_af3_complexes_df)\n",
    "all_failed_af3_complexes_df = pd.concat(all_failed_af3_complexes_df, ignore_index=True)\n",
    "\n",
    "failed_af3_complex_function_annotations = []\n",
    "for pdb_id in set(all_failed_af3_complexes_df[\"pdb_id\"]):\n",
    "    pdb_id = pdb_id.lower().split(\"_\")[0]\n",
    "    if pdb_id == \"?\":\n",
    "        continue\n",
    "    if pdb_id in pdb_info_cache:\n",
    "        pdb_id_info = pdb_info_cache[pdb_id]\n",
    "    else:\n",
    "        pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "        pdb_info_cache[pdb_id] = pdb_id_info\n",
    "    if not pdb_id_info:\n",
    "        continue\n",
    "    failed_af3_complex_function_annotations.append(\n",
    "        # NOTE: these represent functional keywords\n",
    "        pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "        .lower()\n",
    "        .split(\", \")[0]\n",
    "    )\n",
    "\n",
    "failed_af3_complex_function_annotation_counts = subset_counter(\n",
    "    Counter(failed_af3_complex_function_annotations),\n",
    "    complex_function_annotation_counts,\n",
    "    normalize_subset=True,\n",
    ")\n",
    "df = pd.DataFrame(\n",
    "    failed_af3_complex_function_annotation_counts.items(),\n",
    "    columns=[\"Keyword\", \"Failed Ratio\"],\n",
    ")\n",
    "df[\"Frequency\"] = df[\"Keyword\"].map(complex_function_annotation_counts)\n",
    "df.sort_values(by=[\"Failed Ratio\", \"Frequency\"], ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=df, x=\"Failed Ratio\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"Failed Ratio\")\n",
    "plt.ylabel(\"Complex Annotation\")\n",
    "\n",
    "plt.xlim(0, 1.09)\n",
    "\n",
    "# annotate bars with the frequency of each keyword\n",
    "for index, row in df.iterrows():\n",
    "    plt.text(\n",
    "        x=row[\"Failed Ratio\"] + 0.01,\n",
    "        y=index,\n",
    "        s=f\"{row['Failed Ratio']:.2f} ({row['Frequency']})\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"failed_af3_complexes_functional_keywords.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(f\"{len(failed_af3_complex_function_annotations)} complex annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study PDB statistics of different types of complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all CSV files from a custom PDB report\n",
    "report_types = os.listdir(\"pdb_reports\")\n",
    "\n",
    "for report_type in report_types:\n",
    "    pdb_report_dir = os.path.join(\"pdb_reports\", report_type)\n",
    "    pdb_report_files = [\n",
    "        os.path.join(pdb_report_dir, f) for f in os.listdir(pdb_report_dir) if f.endswith(\".csv\")\n",
    "    ]\n",
    "\n",
    "    pdb_report_dfs = []\n",
    "    for pdb_report_file in pdb_report_files:\n",
    "        pdb_report_dfs.append(pd.read_csv(pdb_report_file, skiprows=1))\n",
    "    pdb_report_df = pd.concat(pdb_report_dfs, ignore_index=True)\n",
    "\n",
    "    # analyze and plot statistics of the custom PDB report\n",
    "    pdb_report_df[\"Refinement Resolution (Å)\"] = pdb_report_df[\"Refinement Resolution (Å)\"].astype(\n",
    "        str\n",
    "    )\n",
    "    pdb_report_df[\"Refinement Resolution (Å)\"] = pd.to_numeric(\n",
    "        pdb_report_df[\"Refinement Resolution (Å)\"].str.replace(\",\", \"\"),\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    pdb_report_df[\"Deposition Date\"] = pd.to_datetime(pdb_report_df[\"Deposition Date\"])\n",
    "\n",
    "    pdb_report_df.to_csv(f\"{report_type}_pdb_report.csv\", index=False)\n",
    "\n",
    "    print(f\"{len(pdb_report_df)} PDB entries in the custom {report_type} report.\")\n",
    "\n",
    "    sns.histplot(pdb_report_df[\"Refinement Resolution (Å)\"].values)\n",
    "    plt.xlim(0, 10)\n",
    "    plt.xlabel(\"Refinement Resolution (Å)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{report_type}_pdb_report_resolution.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    sns.histplot(pdb_report_df[\"Deposition Date\"].values)\n",
    "    plt.xlabel(\"Deposition Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{report_type}_pdb_report_deposition_date.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study AlphaFold 3's relationship between training-test set sequence overlap and structure prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PoseBusters Benchmark set and CASP15 complexes that AlphaFold 3 failed to correctly predict\n",
    "for dataset in [\"posebusters_benchmark\", \"casp15\"]:\n",
    "    docking_success_column = \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            (\n",
    "                globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "                == dataset_mapping[dataset]\n",
    "            )\n",
    "            & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] == \"AF3\")\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"{dataset}_complexes_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"{dataset}_complexes_not_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"pdb_id\"].isin(\n",
    "                    globals()[f\"{dataset}_complexes_docked_by_af3_{repeat_index}\"]\n",
    "                ),\n",
    "                \"pdb_id\",\n",
    "            ].unique()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot deposition dates of proteins most similar to AlphaFold 3's failed PoseBusters Benchmark set complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot max sequence overlap deposition dates of AlphaFold 3's failed PoseBusters Benchmark set and CASP15 complexes\n",
    "af3_overlap_datasets = [\"posebusters_benchmark\", \"casp15\"]\n",
    "\n",
    "all_af3_failed_complexes_df = []\n",
    "for dataset in af3_overlap_datasets:\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        failed_complexes_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_complexes_not_docked_by_af3_{repeat_index}\"],\n",
    "            columns=[\"pdb_id\"],\n",
    "        )\n",
    "        failed_complexes_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        failed_complexes_df[\"repeat_index\"] = repeat_index\n",
    "        all_af3_failed_complexes_df.append(failed_complexes_df)\n",
    "all_af3_failed_complexes_df = pd.concat(all_af3_failed_complexes_df, ignore_index=True)\n",
    "all_af3_failed_complex_pdb_ids = list(all_af3_failed_complexes_df.loc[:, \"pdb_id\"].unique())\n",
    "\n",
    "# prepare target and database FASTA files\n",
    "target_fasta = \"target.fasta\"\n",
    "database_fasta = os.path.join(\"..\", \"data\", \"pdb_data\", \"pdb_seqres.txt\")\n",
    "\n",
    "# parse PDB sequences\n",
    "pdb_sequences = parse_fasta(\n",
    "    database_fasta,\n",
    "    only_mols=[\"protein\"],\n",
    "    collate_by_pdb_id=True,\n",
    ")\n",
    "\n",
    "with open(target_fasta, \"w\") as target_f:\n",
    "    for pdb_id in all_af3_failed_complex_pdb_ids:\n",
    "        pdb_id_ = pdb_id.lower().split(\"_\")[0]\n",
    "        if pdb_id_ in pdb_sequences:\n",
    "            for seq in pdb_sequences[pdb_id_]:\n",
    "                target_f.write(f\">{pdb_id_}_{seq[0]}\\n{seq[-1]}\\n\")\n",
    "\n",
    "# run MMseqs2 to find the best match for each PDB chain\n",
    "result_file = \"result.m8\"\n",
    "tmp_dir = \"mmseqs_tmp\"\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"mmseqs\",\n",
    "        \"easy-search\",\n",
    "        target_fasta,\n",
    "        database_fasta,\n",
    "        result_file,\n",
    "        tmp_dir,\n",
    "        \"--format-output\",\n",
    "        \"query,target,pident,qcov,tcov,evalue,bits\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# parse MMseqs2 top match for each PDB chain\n",
    "query_top_match_pdb_id_mappings = dict()\n",
    "if os.path.exists(result_file):\n",
    "    with open(result_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            query_pdb_id = line.strip().split(\"\\t\")[0]\n",
    "            top_match_pdb_id = line.strip().split(\"\\t\")[1]\n",
    "            if (\n",
    "                query_pdb_id not in query_top_match_pdb_id_mappings\n",
    "                and query_pdb_id.split(\"_\")[0] != top_match_pdb_id.split(\"_\")[0]\n",
    "            ):\n",
    "                query_top_match_pdb_id_mappings[query_pdb_id] = top_match_pdb_id\n",
    "\n",
    "    all_af3_failed_complex_pdb_ids = list(query_top_match_pdb_id_mappings.keys())\n",
    "    top_match_pdb_ids = list(query_top_match_pdb_id_mappings.values())\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"No results found. Ensure MMseqs2 is correctly installed and the input sequences are valid.\"\n",
    "    )\n",
    "\n",
    "os.remove(target_fasta)\n",
    "os.remove(result_file)\n",
    "shutil.rmtree(tmp_dir)\n",
    "\n",
    "# find the deposition dates of failed complexes and their top matches\n",
    "failed_complexes = []\n",
    "failed_complex_indices = set()\n",
    "failed_complexes_after_cutoff_deposition_date = []\n",
    "failed_complexes_after_cutoff_deposition_date_indices = set()\n",
    "for failed_complex_index, failed_complex_pdb_id in enumerate(all_af3_failed_complex_pdb_ids):\n",
    "    failed_complex_pdb_id_ = failed_complex_pdb_id.lower().split(\"_\")[0]\n",
    "    if failed_complex_pdb_id_ == \"?\":\n",
    "        continue\n",
    "    if failed_complex_pdb_id_ in pdb_info_cache:\n",
    "        failed_complex_pdb_info = pdb_info_cache[failed_complex_pdb_id_]\n",
    "    else:\n",
    "        failed_complex_pdb_info = pypdb.get_all_info(failed_complex_pdb_id_)\n",
    "        pdb_info_cache[failed_complex_pdb_id_] = failed_complex_pdb_info\n",
    "    if not failed_complex_pdb_info:\n",
    "        continue\n",
    "    deposition_date = failed_complex_pdb_info[\"rcsb_accession_info\"][\"deposit_date\"]\n",
    "    failed_complex_indices.add(failed_complex_index)\n",
    "    failed_complexes.append((failed_complex_pdb_id_, deposition_date))\n",
    "    if deposition_date > method_max_training_cutoff_date:\n",
    "        failed_complexes_after_cutoff_deposition_date_indices.add(failed_complex_index)\n",
    "        failed_complexes_after_cutoff_deposition_date.append(\n",
    "            (failed_complex_pdb_id_, deposition_date)\n",
    "        )\n",
    "\n",
    "top_match_complexes = []\n",
    "top_match_complexes_after_cutoff_deposition_date = []\n",
    "for top_match_index, top_match_pdb_id in enumerate(top_match_pdb_ids):\n",
    "    top_match_pdb_id_ = top_match_pdb_id.lower().split(\"_\")[0]\n",
    "    if top_match_pdb_id_ == \"?\":\n",
    "        continue\n",
    "    if top_match_index not in failed_complex_indices:\n",
    "        continue\n",
    "    if top_match_pdb_id_ in pdb_info_cache:\n",
    "        top_match_pdb_info = pdb_info_cache[top_match_pdb_id_]\n",
    "    else:\n",
    "        top_match_pdb_info = pypdb.get_all_info(top_match_pdb_id_)\n",
    "        pdb_info_cache[top_match_pdb_id_] = top_match_pdb_info\n",
    "    if not top_match_pdb_info:\n",
    "        continue\n",
    "    deposition_date = top_match_pdb_info[\"rcsb_accession_info\"][\"deposit_date\"]\n",
    "    top_match_complexes.append((top_match_pdb_id_, deposition_date))\n",
    "    if top_match_index in failed_complexes_after_cutoff_deposition_date_indices:\n",
    "        top_match_complexes_after_cutoff_deposition_date.append(\n",
    "            (top_match_pdb_id_, deposition_date)\n",
    "        )\n",
    "\n",
    "assert len(failed_complexes) == len(\n",
    "    top_match_complexes\n",
    "), \"Expected equal number of failed complexes and top matches.\"\n",
    "assert len(failed_complexes_after_cutoff_deposition_date) == len(\n",
    "    top_match_complexes_after_cutoff_deposition_date\n",
    "), \"Expected equal number of failed complexes and top matches after the cutoff deposition date.\"\n",
    "\n",
    "# analyze and plot statistics of the failed complexes and their top matches' deposition dates\n",
    "failed_complex_pdb_deposition_dates_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Deposition Date\": [com[1] for com in list(dict.fromkeys(failed_complexes))]\n",
    "    }  # remove chain duplicates in-order\n",
    ")\n",
    "failed_complex_pdb_deposition_dates_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    failed_complex_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    ")\n",
    "failed_complex_pdb_deposition_dates_df.to_csv(\n",
    "    \"af3_failed_complex_pdb_deposition_dates.csv\", index=False\n",
    ")\n",
    "sns.histplot(failed_complex_pdb_deposition_dates_df[\"Deposition Date\"].values, bins=25)\n",
    "plt.xlabel(\"Deposition Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"af3_failed_complex_pdb_deposition_dates.png\")\n",
    "plt.show()\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(\n",
    "    f\"{len(failed_complex_pdb_deposition_dates_df)} date annotations across {af3_overlap_datasets}.\"\n",
    ")\n",
    "\n",
    "top_match_pdb_deposition_dates_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Deposition Date\": [com[1] for com in list(dict.fromkeys(top_match_complexes))]\n",
    "    }  # remove chain duplicates in-order\n",
    ")\n",
    "top_match_pdb_deposition_dates_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    top_match_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    ")\n",
    "top_match_pdb_deposition_dates_df.to_csv(\n",
    "    \"af3_failed_complex_top_match_pdb_deposition_dates.csv\", index=False\n",
    ")\n",
    "sns.histplot(top_match_pdb_deposition_dates_df[\"Deposition Date\"].values, bins=30)\n",
    "plt.xlabel(\"Deposition Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"af3_failed_complex_top_match_pdb_deposition_dates.png\")\n",
    "plt.show()\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(\n",
    "    f\"{len(top_match_pdb_deposition_dates_df)} top match date annotations across {af3_overlap_datasets}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify specific complexes AlphaFold 3 failed to predict that are worth studying further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for failed complexes and their top matches that were both deposited after the cutoff deposition date\n",
    "collated_complexes = defaultdict(list)\n",
    "for failed_complex, top_match_complex in zip(\n",
    "    failed_complexes_after_cutoff_deposition_date, top_match_complexes_after_cutoff_deposition_date\n",
    "):\n",
    "    complex_pdb_id = failed_complex[0]\n",
    "    top_match_pdb_id = top_match_complex[0]\n",
    "    complex_deposition_date = failed_complex[1]\n",
    "    top_match_complex_deposition_date = top_match_complex[1]\n",
    "    collated_complex = (\n",
    "        (complex_pdb_id, complex_deposition_date),\n",
    "        (top_match_pdb_id, top_match_complex_deposition_date),\n",
    "    )\n",
    "    collated_complexes[complex_pdb_id].append(collated_complex)\n",
    "\n",
    "failed_complexes_to_study_further = []\n",
    "failed_complex_pdb_ids_to_study_further = []\n",
    "failed_complex_function_annotations_to_study_further = []\n",
    "for complex_pdb_id in collated_complexes:\n",
    "    collated_complex_chains = collated_complexes[complex_pdb_id]\n",
    "    all_chains_after_cutoff_deposition_date = True\n",
    "    for collated_complex_chain in collated_complex_chains:\n",
    "        (complex_pdb_id, complex_deposition_date), (\n",
    "            top_match_pdb_id,\n",
    "            top_match_complex_deposition_date,\n",
    "        ) = collated_complex_chain\n",
    "        if (\n",
    "            complex_deposition_date <= method_max_training_cutoff_date\n",
    "            or top_match_complex_deposition_date <= method_max_training_cutoff_date\n",
    "        ):\n",
    "            all_chains_after_cutoff_deposition_date = False\n",
    "            break\n",
    "    if all_chains_after_cutoff_deposition_date:\n",
    "        complex_pdb_id_ = complex_pdb_id.lower().split(\"_\")[0]\n",
    "        if complex_pdb_id_ == \"?\":\n",
    "            continue\n",
    "        if complex_pdb_id_ in pdb_info_cache:\n",
    "            complex_pdb_info = pdb_info_cache[complex_pdb_id_]\n",
    "        else:\n",
    "            complex_pdb_info = pypdb.get_all_info(complex_pdb_id_)\n",
    "            pdb_info_cache[complex_pdb_id_] = complex_pdb_info\n",
    "        if not complex_pdb_info:\n",
    "            continue\n",
    "        complex_function_annotation = (\n",
    "            # NOTE: these represent functional keywords\n",
    "            complex_pdb_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "        failed_complexes_to_study_further.append(collated_complex_chains)\n",
    "        failed_complex_pdb_ids_to_study_further.append(complex_pdb_id)\n",
    "        failed_complex_function_annotations_to_study_further.append(complex_function_annotation)\n",
    "        print(f\"{complex_pdb_id}, {complex_function_annotation} : {collated_complex_chains}\")\n",
    "\n",
    "for complex_index, (complex_pdb_id, complex_function_annotation) in enumerate(\n",
    "    zip(\n",
    "        failed_complex_pdb_ids_to_study_further,\n",
    "        failed_complex_function_annotations_to_study_further,\n",
    "    )\n",
    "):\n",
    "    if complex_index == 0:\n",
    "        print()\n",
    "    pb_path = os.path.join(\n",
    "        \"..\", \"data\", \"posebusters_benchmark_set\", f\"{complex_pdb_id.upper()}_*\", \"*.pdb\"\n",
    "    )\n",
    "    if glob.glob(pb_path):\n",
    "        pb_path = glob.glob(pb_path)[0]\n",
    "        print(\n",
    "            f\"Posebusters Benchmark target: {complex_pdb_id}, {complex_function_annotation} -> {pb_path}\"\n",
    "        )\n",
    "    else:\n",
    "        casp_matches = [k for k, v in casp15_target_pdb_id_mapping.items() if v == complex_pdb_id]\n",
    "        print(f\"CASP15 target: {complex_pdb_id}, {complex_function_annotation} -> {casp_matches}\")\n",
    "\n",
    "print(\n",
    "    f\"{len(failed_complexes_to_study_further)} ((failed complex, deposition date), (top match, deposition date)) novel (multi-chain) protein-ligand PDB complexes AlphaFold 3 failed to predict that are worth studying further.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoseBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
