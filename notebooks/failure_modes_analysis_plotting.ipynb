{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Modes Analysis Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypdb\n",
    "import seaborn as sns\n",
    "from beartype.typing import Any, Dict, List, Optional, Tuple\n",
    "from pdbeccdutils.core import ccd_reader\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "from posebench.analysis.inference_analysis import BUST_TEST_COLUMNS\n",
    "from posebench.utils.data_utils import parse_fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General variables\n",
    "baseline_methods = [\n",
    "    \"vina_p2rank\",\n",
    "    \"diffdock\",\n",
    "    \"dynamicbind\",\n",
    "    \"neuralplexer\",\n",
    "    \"rfaa\",\n",
    "    \"chai-lab_ss\",\n",
    "    # \"chai-lab\",\n",
    "    \"alphafold3_ss\",\n",
    "    \"alphafold3\",\n",
    "]\n",
    "max_num_repeats_per_method = 3\n",
    "method_max_training_cutoff_date = \"2021-09-30\"\n",
    "\n",
    "datasets = [\"astex_diverse\", \"posebusters_benchmark\", \"dockgen\", \"casp15\"]\n",
    "\n",
    "# Filepaths for each baseline method\n",
    "globals()[\"vina_output_dir\"] = os.path.join(\"..\", \"forks\", \"Vina\", \"inference\")\n",
    "globals()[\"diffdock_output_dir\"] = os.path.join(\"..\", \"forks\", \"DiffDock\", \"inference\")\n",
    "globals()[\"dynamicbind_output_dir\"] = os.path.join(\n",
    "    \"..\", \"forks\", \"DynamicBind\", \"inference\", \"outputs\", \"results\"\n",
    ")\n",
    "globals()[\"neuralplexer_output_dir\"] = os.path.join(\"..\", \"forks\", \"NeuralPLexer\", \"inference\")\n",
    "globals()[\"rfaa_output_dir\"] = os.path.join(\"..\", \"forks\", \"RoseTTAFold-All-Atom\", \"inference\")\n",
    "globals()[\"chai-lab_output_dir\"] = os.path.join(\"..\", \"forks\", \"chai-lab\", \"inference\")\n",
    "globals()[\"alphafold3_output_dir\"] = os.path.join(\"..\", \"forks\", \"alphafold3\", \"inference\")\n",
    "globals()[\"casp15_output_dir\"] = os.path.join(\"..\", \"data\", \"test_cases\", \"casp15\")\n",
    "for config in [\"\", \"_relaxed\"]:\n",
    "    for dataset in datasets:\n",
    "        for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "            # P2Rank-Vina results\n",
    "            globals()[\n",
    "                f\"vina_p2rank_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"vina_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_vina_p2rank_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"vina_p2rank_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # DiffDock results\n",
    "            globals()[f\"diffdock_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"diffdock_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_diffdock_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"diffdock_{dataset}_output_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # DynamicBind results\n",
    "            globals()[\n",
    "                f\"dynamicbind_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"dynamicbind_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_dynamicbind_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"{dataset}_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # NeuralPLexer results\n",
    "            globals()[\n",
    "                f\"neuralplexer_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"neuralplexer_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_neuralplexer_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"neuralplexer_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # RoseTTAFold-All-Atom results\n",
    "            globals()[f\"rfaa_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"rfaa_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_rfaa_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"rfaa_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Chai-1 (Single-Seq) results\n",
    "            globals()[\n",
    "                f\"chai-lab_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"chai-lab_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_chai-lab_ss_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"chai-lab_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # Chai-1 results\n",
    "            globals()[f\"chai-lab_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"chai-lab_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_chai-lab_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"chai-lab_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # AlphaFold 3 (Single-Seq) results\n",
    "            globals()[\n",
    "                f\"alphafold3_ss_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "            ] = os.path.join(\n",
    "                (\n",
    "                    globals()[\"casp15_output_dir\"] + config\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\"alphafold3_output_dir\"]\n",
    "                ),\n",
    "                (\n",
    "                    f\"top_alphafold3_ss_ensemble_predictions_{repeat_index}\"\n",
    "                    if dataset == \"casp15\"\n",
    "                    else f\"alphafold3_ss_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                ),\n",
    "                \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "            )\n",
    "\n",
    "            # AlphaFold 3 results\n",
    "            globals()[f\"alphafold3_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"] = (\n",
    "                os.path.join(\n",
    "                    (\n",
    "                        globals()[\"casp15_output_dir\"] + config\n",
    "                        if dataset == \"casp15\"\n",
    "                        else globals()[\"alphafold3_output_dir\"]\n",
    "                    ),\n",
    "                    (\n",
    "                        f\"top_alphafold3_ensemble_predictions_{repeat_index}\"\n",
    "                        if dataset == \"casp15\"\n",
    "                        else f\"alphafold3_{dataset}_outputs_{repeat_index}{config}\"\n",
    "                    ),\n",
    "                    \"scoring_results.csv\" if dataset == \"casp15\" else \"bust_results.csv\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Mappings\n",
    "method_mapping = {\n",
    "    \"vina_p2rank\": \"P2Rank-Vina\",\n",
    "    \"diffdock\": \"DiffDock-L\",\n",
    "    \"dynamicbind\": \"DynamicBind\",\n",
    "    \"neuralplexer\": \"NeuralPLexer\",\n",
    "    \"rfaa\": \"RoseTTAFold-AA\",\n",
    "    \"chai-lab_ss\": \"Chai-1-Single-Seq\",\n",
    "    # \"chai-lab\": \"Chai-1\",\n",
    "    \"alphafold3_ss\": \"AF3-Single-Seq\",\n",
    "    \"alphafold3\": \"AF3\",\n",
    "}\n",
    "\n",
    "method_category_mapping = {\n",
    "    \"vina_p2rank\": \"Conventional blind\",\n",
    "    \"diffdock\": \"DL-based blind\",\n",
    "    \"dynamicbind\": \"DL-based blind\",\n",
    "    \"neuralplexer\": \"DL-based blind\",\n",
    "    \"rfaa\": \"DL-based blind\",\n",
    "    \"chai-lab_ss\": \"DL-based blind\",\n",
    "    # \"chai-lab\": \"DL-based blind\",\n",
    "    \"alphafold3_ss\": \"DL-based blind\",\n",
    "    \"alphafold3\": \"DL-based blind\",\n",
    "}\n",
    "\n",
    "dataset_mapping = {\n",
    "    \"astex_diverse\": \"Astex Diverse set\",\n",
    "    \"posebusters_benchmark\": \"Posebusters Benchmark set\",\n",
    "    \"dockgen\": \"DockGen set\",\n",
    "    \"casp15\": \"CASP15 set\",\n",
    "}\n",
    "\n",
    "casp15_target_pdb_id_mapping = {\n",
    "    # NOTE: `?` indicates that the target's crystal structure is not publicly available\n",
    "    \"H1135\": \"7z8y\",\n",
    "    \"H1171v1\": \"7pbl\",\n",
    "    \"H1171v2\": \"7pbl\",\n",
    "    \"H1172v1\": \"7pbp\",\n",
    "    \"H1172v2\": \"7pbp\",\n",
    "    \"H1172v3\": \"7pbp\",\n",
    "    \"H1172v4\": \"7pbp\",\n",
    "    \"T1124\": \"7ux8\",\n",
    "    \"T1127v2\": \"?\",\n",
    "    \"T1146\": \"?\",\n",
    "    \"T1152\": \"7r1l\",\n",
    "    \"T1158v1\": \"8sx8\",\n",
    "    \"T1158v2\": \"8sxb\",\n",
    "    \"T1158v3\": \"8sx7\",\n",
    "    \"T1158v4\": \"8swn\",\n",
    "    \"T1170\": \"7pbr\",\n",
    "    \"T1181\": \"?\",\n",
    "    \"T1186\": \"?\",\n",
    "    \"T1187\": \"8ad2\",\n",
    "    \"T1188\": \"8c6z\",\n",
    "}\n",
    "\n",
    "ligand_prediction_methods = set(method_mapping.values()) - {\n",
    "    # NOTE: we exclude Vina in this analysis since it often is missing predictions due to timeouts\n",
    "    \"P2Rank-Vina\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test results for each baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and report test results for each baseline method\n",
    "for config in [\"\"]:\n",
    "    for dataset in datasets:\n",
    "        for method in baseline_methods:\n",
    "            for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "                method_title = method_mapping[method]\n",
    "\n",
    "                if not os.path.exists(\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "                    ]\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"] = (\n",
    "                    pd.read_csv(\n",
    "                        globals()[\n",
    "                            f\"{method}_{dataset}{config}_bust_results_csv_filepath_{repeat_index}\"\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if dataset == \"casp15\":\n",
    "                    # count the number of ligands in each target complex, and assign these corresponding numbers to the ligands (rows) of each complex\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"num_target_ligands\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "                        .groupby([\"target\", \"mdl\"])[\"pose\"]\n",
    "                        .transform(\"count\")\n",
    "                    )\n",
    "\n",
    "                    # filter out non-relevant ligand predictions, and for all methods select only their first model for each ligand\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        np.where(\n",
    "                            (\n",
    "                                globals()[\n",
    "                                    f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                                ].relevant\n",
    "                            ),\n",
    "                            True,\n",
    "                            False,\n",
    "                        )\n",
    "                        & (\n",
    "                            globals()[\n",
    "                                f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                            ].mdl\n",
    "                            == 1\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                    # finalize bust (i.e., scoring) results for CASP15, using dummy values for `pb_valid` and `crmsd_≤_1å`\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"rmsd_≤_2å\"\n",
    "                    ] = (\n",
    "                        globals()[\n",
    "                            f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                        ].loc[:, \"rmsd\"]\n",
    "                        <= 2\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pdb_valid\"\n",
    "                    ] = True\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"crmsd_≤_1å\"\n",
    "                    ] = True\n",
    "\n",
    "                else:\n",
    "                    globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ] = globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                        BUST_TEST_COLUMNS + [\"rmsd\", \"centroid_distance\", \"inchi_crystal\"]\n",
    "                    ]\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"pb_valid\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "                        .iloc[:, 1:-3]\n",
    "                        .all(axis=1)\n",
    "                    )\n",
    "                    globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                        :, \"crmsd_≤_1å\"\n",
    "                    ] = (\n",
    "                        globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"][\n",
    "                            \"centroid_distance\"\n",
    "                        ]\n",
    "                        < 1\n",
    "                    )\n",
    "\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"method\"\n",
    "                ] = method\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"post-processing\"\n",
    "                ] = (\"energy minimization\" if config == \"_relaxed\" else \"none\")\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"dataset\"\n",
    "                ] = dataset\n",
    "                globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"].loc[\n",
    "                    :, \"docked_ligand_successfully_loaded\"\n",
    "                ] = (\n",
    "                    True\n",
    "                    if dataset == \"casp15\"\n",
    "                    else globals()[\n",
    "                        f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"\n",
    "                    ][[\"mol_pred_loaded\", \"mol_true_loaded\", \"mol_cond_loaded\"]].all(axis=1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_method_index(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Assign method index for plotting.\n",
    "\n",
    "    :param method: Method name.\n",
    "    :return: Method index.\n",
    "    \"\"\"\n",
    "    return list(method_mapping.keys()).index(method)\n",
    "\n",
    "\n",
    "def categorize_method(method: str) -> str:\n",
    "    \"\"\"\n",
    "    Categorize method for plotting.\n",
    "\n",
    "    :param method: Method name.\n",
    "    :return: Method category.\n",
    "    \"\"\"\n",
    "    return method_category_mapping.get(method, \"Misc\")\n",
    "\n",
    "\n",
    "def find_closest_inchi(\n",
    "    target_inchi: str, inchi_list: List[str], candidate_fp_cache: Optional[Dict[str, Any]] = None\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Find the closest InChI string to the target InChI string from a list of InChI strings.\n",
    "\n",
    "    :param target_inchi: Target InChI string.\n",
    "    :param inchi_list: List of InChI strings.\n",
    "    :param candidate_fp_cache: Optional cache of candidate fingerprints.\n",
    "    :return: Closest InChI string and its Tanimoto similarity.\n",
    "    \"\"\"\n",
    "    target_mol = Chem.MolFromInchi(target_inchi)\n",
    "    target_fp = AllChem.GetMorganFingerprintAsBitVect(target_mol, radius=2, nBits=2048)\n",
    "\n",
    "    best_match = None\n",
    "    highest_similarity = 0\n",
    "\n",
    "    for candidate_inchi in tqdm(inchi_list, desc=\"Finding closest InChI\"):\n",
    "        if candidate_inchi in candidate_fp_cache:\n",
    "            candidate_fp = candidate_fp_cache[candidate_inchi]\n",
    "        else:\n",
    "            candidate_mol = Chem.MolFromInchi(candidate_inchi)\n",
    "            if candidate_mol is None:\n",
    "                continue\n",
    "            candidate_fp = AllChem.GetMorganFingerprintAsBitVect(\n",
    "                candidate_mol, radius=2, nBits=2048\n",
    "            )\n",
    "            candidate_fp_cache[candidate_inchi] = candidate_fp\n",
    "\n",
    "        similarity = TanimotoSimilarity(target_fp, candidate_fp)\n",
    "\n",
    "        if similarity == 1.0:\n",
    "            return candidate_inchi, similarity\n",
    "        elif similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_match = candidate_inchi\n",
    "\n",
    "    return best_match, highest_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and organize the results CSVs\n",
    "for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "    globals()[f\"results_table_{repeat_index}\"] = pd.concat(\n",
    "        [\n",
    "            globals()[f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\"]\n",
    "            for dataset in datasets\n",
    "            for method in baseline_methods\n",
    "            for config in [\"\"]\n",
    "            if f\"{method}_{dataset}{config}_bust_results_table_{repeat_index}\" in globals()\n",
    "        ]\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method_category\"] = globals()[\n",
    "        f\"results_table_{repeat_index}\"\n",
    "    ][\"method\"].apply(categorize_method)\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method_assignment_index\"] = globals()[\n",
    "        f\"results_table_{repeat_index}\"\n",
    "    ][\"method\"].apply(assign_method_index)\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"crmsd_within_threshold\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"crmsd_≤_1å\"].fillna(False)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_≤_2å\"].fillna(False)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold_and_pb_valid\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"rmsd_within_threshold\"]\n",
    "    ) & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"pb_valid\"].fillna(False))\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"RMSD ≤ 2 Å & PB-Valid\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"rmsd_within_threshold_and_pb_valid\"]\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"cRMSD ≤ 1 Å\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"crmsd_within_threshold\"]\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"RMSD ≤ 2 Å\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"]\n",
    "        .loc[:, \"rmsd_within_threshold\"]\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"].map(dataset_mapping)\n",
    "    )\n",
    "    globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] = (\n",
    "        globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"].map(method_mapping)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Ligand Expo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCD_COMPONENTS_FILEPATH = os.path.join(\"..\", \"data\", \"ccd_data\", \"components.cif\")\n",
    "CCD_COMPONENTS_INCHI_FILEPATH = os.path.join(\"..\", \"data\", \"ccd_data\", \"components_inchi.json\")\n",
    "\n",
    "# load all InChI strings in the PDB Chemical Component Dictionary (CCD)\n",
    "\n",
    "CCD_COMPONENTS_INCHI = None\n",
    "\n",
    "if os.path.exists(CCD_COMPONENTS_INCHI_FILEPATH):\n",
    "    print(f\"Loading CCD component InChI strings from {CCD_COMPONENTS_INCHI_FILEPATH}.\")\n",
    "    with open(CCD_COMPONENTS_INCHI_FILEPATH) as f:\n",
    "        CCD_COMPONENTS_INCHI = json.load(f)\n",
    "elif os.path.exists(CCD_COMPONENTS_FILEPATH):\n",
    "    print(\n",
    "        f\"Loading CCD components from {CCD_COMPONENTS_FILEPATH} to extract all available InChI strings (~3 minutes, one-time only).\"\n",
    "    )\n",
    "    CCD_COMPONENTS = ccd_reader.read_pdb_components_file(\n",
    "        CCD_COMPONENTS_FILEPATH,\n",
    "        sanitize=False,  # Reduce loading time\n",
    "    )\n",
    "    print(\n",
    "        f\"Saving CCD component InChI strings to {CCD_COMPONENTS_INCHI_FILEPATH} (one-time only).\"\n",
    "    )\n",
    "    with open(CCD_COMPONENTS_INCHI_FILEPATH, \"w\") as f:\n",
    "        CCD_COMPONENTS_INCHI = {\n",
    "            CCD_COMPONENTS[ccd_code].component.inchi: {\n",
    "                \"atoms_ids\": CCD_COMPONENTS[ccd_code].component.atoms_ids,\n",
    "                \"formula\": CCD_COMPONENTS[ccd_code].component.formula,\n",
    "                \"id\": CCD_COMPONENTS[ccd_code].component.id,\n",
    "                \"inchikey\": CCD_COMPONENTS[ccd_code].component.inchikey,\n",
    "                \"modified_date\": str(CCD_COMPONENTS[ccd_code].component.modified_date),\n",
    "                \"name\": CCD_COMPONENTS[ccd_code].component.name,\n",
    "                \"number_atoms\": CCD_COMPONENTS[ccd_code].component.number_atoms,\n",
    "                \"pdb_id\": CCD_COMPONENTS[ccd_code].component.ccd_cif_block.find(\n",
    "                    \"_chem_comp.\", [\"pdbx_model_coordinates_db_code\"]\n",
    "                )[0][0],\n",
    "                \"released\": CCD_COMPONENTS[ccd_code].component.released,\n",
    "                \"smiles\": Chem.MolToSmiles(CCD_COMPONENTS[ccd_code].component.mol_no_h),\n",
    "                \"weight\": CCD_COMPONENTS[ccd_code].component._cif_properties.weight,\n",
    "            }\n",
    "            for ccd_code in CCD_COMPONENTS\n",
    "        }\n",
    "        json.dump(CCD_COMPONENTS_INCHI, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect metadata across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find InChI keys of ligands across all datasets\n",
    "ccd_components_inchi_fp_cache = dict()\n",
    "ccd_components_inchi_keys = list(CCD_COMPONENTS_INCHI)\n",
    "\n",
    "for dataset in datasets:\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "            == dataset_mapping[dataset]\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"inchi_crystal\"] = (\n",
    "                dataset_results_table.loc[:, \"target\"].astype(str)\n",
    "                + \"_\"\n",
    "                + dataset_results_table.loc[:, \"ref_lig\"].astype(str)\n",
    "            )\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"ligands_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[:, \"inchi_crystal\"].unique()\n",
    "        )\n",
    "\n",
    "        # collect metadata of ligands for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by all methods\n",
    "        globals()[f\"{dataset}_ligands_{repeat_index}\"] = []\n",
    "        for ligand in tqdm(\n",
    "            globals()[f\"ligands_{repeat_index}\"],\n",
    "            desc=f\"Processing {dataset}_{repeat_index} ligands\",\n",
    "        ):\n",
    "            ligand_results = dataset_results_table.loc[\n",
    "                dataset_results_table.loc[:, \"inchi_crystal\"] == ligand\n",
    "            ]\n",
    "            ligand_result_methods = set(ligand_results.loc[:, \"method\"].unique())\n",
    "            if ligand_result_methods >= ligand_prediction_methods:\n",
    "                row = ligand_results.iloc[0]\n",
    "\n",
    "                if dataset == \"casp15\":\n",
    "                    row_inchi = {\n",
    "                        \"name\": row.inchi_crystal,\n",
    "                        \"pdb_id\": row.pdb_id,\n",
    "                    }\n",
    "                    globals()[f\"{dataset}_ligands_{repeat_index}\"].append(row_inchi)\n",
    "                    continue\n",
    "\n",
    "                row_inchi = CCD_COMPONENTS_INCHI.get(row.inchi_crystal)\n",
    "                if not row_inchi:\n",
    "                    # (slowly) find the closest matching CCD component InChI string if necessary (e.g., for DockGen)\n",
    "                    closest_inchi, closest_inchi_similarity = find_closest_inchi(\n",
    "                        row.inchi_crystal,\n",
    "                        ccd_components_inchi_keys,\n",
    "                        candidate_fp_cache=ccd_components_inchi_fp_cache,\n",
    "                    )\n",
    "                    row_inchi = CCD_COMPONENTS_INCHI[closest_inchi]\n",
    "                    print(\n",
    "                        f\"Found closest CCD component InChI string (similarity={closest_inchi_similarity}) for: {ligand}\"\n",
    "                    )\n",
    "                if row_inchi:\n",
    "                    # if row_inchi and row_inchi[\"modified_date\"] > method_max_training_cutoff_date:\n",
    "                    print(f\"{dataset_mapping[dataset]} docking case for: {ligand}\")\n",
    "                    print(f\"CCD component InChI metadata: {row_inchi}\\n\")\n",
    "                    globals()[f\"{dataset}_ligands_{repeat_index}\"].append(row_inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distribution of protein types across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of the ligands across all datasets\n",
    "pdb_info_cache = dict()\n",
    "\n",
    "for repeat_index in [1]:  # NOTE: we only consider the first repeat\n",
    "    all_ligands_df = []\n",
    "    for dataset in datasets:\n",
    "        ligands_df = pd.DataFrame(globals()[f\"{dataset}_ligands_{repeat_index}\"])\n",
    "        ligands_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        all_ligands_df.append(ligands_df)\n",
    "    all_ligands_df = pd.concat(all_ligands_df, ignore_index=True)\n",
    "\n",
    "    if all_ligands_df.empty:\n",
    "        print(\"No ligands for any dataset.\")\n",
    "        continue\n",
    "\n",
    "    ligand_function_annotations = []\n",
    "    for pdb_id in set(all_ligands_df[\"pdb_id\"]):\n",
    "        pdb_id = pdb_id.lower()\n",
    "        if pdb_id == \"?\":\n",
    "            continue\n",
    "        if pdb_id in pdb_info_cache:\n",
    "            pdb_id_info = pdb_info_cache[pdb_id]\n",
    "        else:\n",
    "            pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "            pdb_info_cache[pdb_id] = pdb_id_info\n",
    "        if not pdb_id_info:\n",
    "            continue\n",
    "        ligand_function_annotations.append(\n",
    "            # NOTE: these represent functional keywords\n",
    "            pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "\n",
    "    ligand_function_annotation_counts = Counter(ligand_function_annotations)\n",
    "    df = pd.DataFrame(\n",
    "        ligand_function_annotation_counts.items(),\n",
    "        columns=[\"Keyword\", \"Frequency\"],\n",
    "    )\n",
    "    df[\"Frequency\"] = df[\"Frequency\"].astype(int)\n",
    "    df = df.sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    sns.barplot(data=df, x=\"Frequency\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "    max_freq = df[\"Frequency\"].max()\n",
    "    plt.xticks(ticks=range(0, max_freq + 1), labels=range(0, max_freq + 1))\n",
    "\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Protein Annotation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"ligands_functional_keywords_{repeat_index}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"{len(ligand_function_annotations)} annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify failure modes across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find InChI keys of ligands for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by any method\n",
    "for dataset in datasets:\n",
    "    # NOTE: for DockGen, we consider centroid RMSD (cRMSD) ≤ 1 Å as a surrogate docking success criterion\n",
    "    docking_success_column = \"cRMSD ≤ 1 Å\" if dataset == \"dockgen\" else \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "            == dataset_mapping[dataset]\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"inchi_crystal\"] = (\n",
    "                dataset_results_table.loc[:, \"target\"].astype(str)\n",
    "                + \"_\"\n",
    "                + dataset_results_table.loc[:, \"ref_lig\"].astype(str)\n",
    "            )\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"ligands_docked_by_any_method_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"inchi_crystal\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"ligands_not_docked_by_any_method_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"inchi_crystal\"].isin(\n",
    "                    globals()[f\"ligands_docked_by_any_method_{repeat_index}\"]\n",
    "                ),\n",
    "                \"inchi_crystal\",\n",
    "            ].unique()\n",
    "        )\n",
    "\n",
    "        # collect metadata of ligands for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by all methods\n",
    "        globals()[f\"{dataset}_failed_ligands_{repeat_index}\"] = []\n",
    "        for ligand in tqdm(\n",
    "            globals()[f\"ligands_not_docked_by_any_method_{repeat_index}\"],\n",
    "            desc=f\"Processing {dataset}_{repeat_index} failed ligands\",\n",
    "        ):\n",
    "            ligand_results = dataset_results_table.loc[\n",
    "                dataset_results_table.loc[:, \"inchi_crystal\"] == ligand\n",
    "            ]\n",
    "            ligand_result_methods = set(ligand_results.loc[:, \"method\"].unique())\n",
    "            if ligand_result_methods >= ligand_prediction_methods:\n",
    "                row = ligand_results.iloc[0]\n",
    "\n",
    "                if dataset == \"casp15\":\n",
    "                    row_inchi = {\n",
    "                        \"name\": row.inchi_crystal,\n",
    "                        \"pdb_id\": row.pdb_id,\n",
    "                    }\n",
    "                    globals()[f\"{dataset}_failed_ligands_{repeat_index}\"].append(row_inchi)\n",
    "                    continue\n",
    "\n",
    "                row_inchi = CCD_COMPONENTS_INCHI.get(row.inchi_crystal)\n",
    "                if not row_inchi:\n",
    "                    # (slowly) find the closest matching CCD component InChI string if necessary (e.g., for DockGen)\n",
    "                    closest_inchi, closest_inchi_similarity = find_closest_inchi(\n",
    "                        row.inchi_crystal,\n",
    "                        ccd_components_inchi_keys,\n",
    "                        candidate_fp_cache=ccd_components_inchi_fp_cache,\n",
    "                    )\n",
    "                    row_inchi = CCD_COMPONENTS_INCHI[closest_inchi]\n",
    "                    print(\n",
    "                        f\"Found closest CCD component InChI string (similarity={closest_inchi_similarity}) for: {ligand}\"\n",
    "                    )\n",
    "                if row_inchi:\n",
    "                    # if row_inchi and row_inchi[\"modified_date\"] > method_max_training_cutoff_date:\n",
    "                    print(f\"Failed {dataset_mapping[dataset]} docking case for: {ligand}\")\n",
    "                    print(f\"CCD component InChI metadata: {row_inchi}\\n\")\n",
    "                    globals()[f\"{dataset}_failed_ligands_{repeat_index}\"].append(row_inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record and plot failure mode metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot statistics of the failed ligands\n",
    "pd.options.mode.copy_on_write = False\n",
    "\n",
    "for dataset in datasets:\n",
    "    if dataset == \"casp15\":\n",
    "        # NOTE: we do not parse CASP15's failed ligand metadata for now\n",
    "        continue\n",
    "\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        failed_ligands_df = pd.DataFrame(globals()[f\"{dataset}_failed_ligands_{repeat_index}\"])\n",
    "        if failed_ligands_df.empty:\n",
    "            print(f\"No failed ligands for {dataset}.\")\n",
    "            continue\n",
    "\n",
    "        failed_ligands_df[\"weight\"] = failed_ligands_df[\"weight\"].astype(float)\n",
    "        failed_ligands_df[\"number_atoms\"] = failed_ligands_df[\"number_atoms\"].astype(int)\n",
    "\n",
    "        failed_ligands_df.to_csv(f\"{dataset}_failed_ligands.csv\", index=False)\n",
    "\n",
    "        sns.histplot(failed_ligands_df[\"number_atoms\"].values)\n",
    "        plt.xlabel(\"Number of Atoms\")\n",
    "        plt.savefig(f\"{dataset}_failed_ligands_number_atoms.png\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        sns.histplot(failed_ligands_df[\"weight\"].values)\n",
    "        plt.xlabel(\"Molecular Weight\")\n",
    "        plt.savefig(f\"{dataset}_failed_ligands_weight.png\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find commonalities among the failure modes of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of the failed ligands across all datasets\n",
    "for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "    all_failed_ligands_df = []\n",
    "    for dataset in datasets:\n",
    "        failed_ligands_df = pd.DataFrame(globals()[f\"{dataset}_failed_ligands_{repeat_index}\"])\n",
    "        failed_ligands_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        all_failed_ligands_df.append(failed_ligands_df)\n",
    "    all_failed_ligands_df = pd.concat(all_failed_ligands_df, ignore_index=True)\n",
    "\n",
    "    if all_failed_ligands_df.empty:\n",
    "        print(\"No failed ligands for any dataset.\")\n",
    "        continue\n",
    "\n",
    "    failed_ligand_function_annotations = []\n",
    "    for pdb_id in set(all_failed_ligands_df[\"pdb_id\"]):\n",
    "        pdb_id = pdb_id.lower()\n",
    "        if pdb_id == \"?\":\n",
    "            continue\n",
    "        if pdb_id in pdb_info_cache:\n",
    "            pdb_id_info = pdb_info_cache[pdb_id]\n",
    "        else:\n",
    "            pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "            pdb_info_cache[pdb_id] = pdb_id_info\n",
    "        if not pdb_id_info:\n",
    "            continue\n",
    "        failed_ligand_function_annotations.append(\n",
    "            # NOTE: these represent functional keywords\n",
    "            pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "            .lower()\n",
    "            .split(\", \")[0]\n",
    "        )\n",
    "\n",
    "    failed_ligand_function_annotation_counts = Counter(failed_ligand_function_annotations)\n",
    "    df = pd.DataFrame(\n",
    "        failed_ligand_function_annotation_counts.items(),\n",
    "        columns=[\"Keyword\", \"Frequency\"],\n",
    "    )\n",
    "    df[\"Frequency\"] = df[\"Frequency\"].astype(int)\n",
    "    df = df.sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df, x=\"Frequency\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "    max_freq = df[\"Frequency\"].max()\n",
    "    plt.xticks(ticks=range(0, max_freq + 1), labels=range(0, max_freq + 1))\n",
    "\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Protein Annotation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"failed_ligands_functional_keywords_{repeat_index}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    print(f\"{len(failed_ligand_function_annotations)} annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify AlphaFold 3's failure modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ligands that AlphaFold 3 failed to correctly predict\n",
    "for dataset in datasets:\n",
    "    # NOTE: for DockGen, we consider centroid RMSD (cRMSD) ≤ 1 Å as a surrogate docking success criterion\n",
    "    docking_success_column = \"cRMSD ≤ 1 Å\" if dataset == \"dockgen\" else \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            (\n",
    "                globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "                == dataset_mapping[dataset]\n",
    "            )\n",
    "            & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] == \"AF3\")\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"inchi_crystal\"] = (\n",
    "                dataset_results_table.loc[:, \"target\"].astype(str)\n",
    "                + \"_\"\n",
    "                + dataset_results_table.loc[:, \"ref_lig\"].astype(str)\n",
    "            )\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"ligands_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"inchi_crystal\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"ligands_not_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"inchi_crystal\"].isin(\n",
    "                    globals()[f\"ligands_docked_by_af3_{repeat_index}\"]\n",
    "                ),\n",
    "                \"inchi_crystal\",\n",
    "            ].unique()\n",
    "        )\n",
    "\n",
    "        # collect metadata of ligands for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by AlphaFold 3\n",
    "        globals()[f\"{dataset}_af3_failed_ligands_{repeat_index}\"] = []\n",
    "        for ligand in tqdm(\n",
    "            globals()[f\"ligands_not_docked_by_af3_{repeat_index}\"],\n",
    "            desc=f\"Processing {dataset} AF3 failed ligands\",\n",
    "        ):\n",
    "            ligand_results = dataset_results_table.loc[\n",
    "                dataset_results_table.loc[:, \"inchi_crystal\"] == ligand\n",
    "            ]\n",
    "            row = ligand_results.iloc[0]\n",
    "\n",
    "            if dataset == \"casp15\":\n",
    "                row_inchi = {\n",
    "                    \"name\": row.inchi_crystal,\n",
    "                    \"pdb_id\": row.pdb_id,\n",
    "                }\n",
    "                globals()[f\"{dataset}_af3_failed_ligands_{repeat_index}\"].append(row_inchi)\n",
    "                continue\n",
    "\n",
    "            row_inchi = CCD_COMPONENTS_INCHI.get(row.inchi_crystal)\n",
    "            if not row_inchi:\n",
    "                # (slowly) find the closest matching CCD component InChI string if necessary (e.g., for DockGen)\n",
    "                closest_inchi, closest_inchi_similarity = find_closest_inchi(\n",
    "                    row.inchi_crystal,\n",
    "                    ccd_components_inchi_keys,\n",
    "                    candidate_fp_cache=ccd_components_inchi_fp_cache,\n",
    "                )\n",
    "                row_inchi = CCD_COMPONENTS_INCHI[closest_inchi]\n",
    "                print(\n",
    "                    f\"Found closest CCD component InChI string (similarity={closest_inchi_similarity}) for: {ligand}\"\n",
    "                )\n",
    "            if row_inchi:\n",
    "                # if row_inchi and row_inchi[\"modified_date\"] > method_max_training_cutoff_date:\n",
    "                print(f\"Failed {dataset_mapping[dataset]} AF3 docking case for: {ligand}\")\n",
    "                print(f\"CCD component InChI metadata: {row_inchi}\\n\")\n",
    "                globals()[f\"{dataset}_af3_failed_ligands_{repeat_index}\"].append(row_inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record and plot AlphaFold 3's failure mode metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functional keyword statistics of AlphaFold 3's failed ligands across all datasets\n",
    "all_failed_ligands_df = []\n",
    "for dataset in datasets:\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        failed_ligands_df = pd.DataFrame(globals()[f\"{dataset}_af3_failed_ligands_{repeat_index}\"])\n",
    "        failed_ligands_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        failed_ligands_df[\"repeat_index\"] = repeat_index\n",
    "        all_failed_ligands_df.append(failed_ligands_df)\n",
    "all_failed_ligands_df = pd.concat(all_failed_ligands_df, ignore_index=True)\n",
    "\n",
    "failed_ligand_function_annotations = []\n",
    "for pdb_id in set(all_failed_ligands_df[\"pdb_id\"]):\n",
    "    pdb_id = pdb_id.lower()\n",
    "    if pdb_id == \"?\":\n",
    "        continue\n",
    "    if pdb_id in pdb_info_cache:\n",
    "        pdb_id_info = pdb_info_cache[pdb_id]\n",
    "    else:\n",
    "        pdb_id_info = pypdb.get_all_info(pdb_id)\n",
    "        pdb_info_cache[pdb_id] = pdb_id_info\n",
    "    if not pdb_id_info:\n",
    "        continue\n",
    "    failed_ligand_function_annotations.append(\n",
    "        # NOTE: these represent functional keywords\n",
    "        pdb_id_info[\"struct_keywords\"][\"pdbx_keywords\"]\n",
    "        .lower()\n",
    "        .split(\", \")[0]\n",
    "    )\n",
    "\n",
    "failed_ligand_function_annotation_counts = Counter(failed_ligand_function_annotations)\n",
    "df = pd.DataFrame(\n",
    "    failed_ligand_function_annotation_counts.items(),\n",
    "    columns=[\"Keyword\", \"Frequency\"],\n",
    ")\n",
    "df[\"Frequency\"] = df[\"Frequency\"].astype(int)\n",
    "df = df.sort_values(by=\"Frequency\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=df, x=\"Frequency\", y=\"Keyword\", palette=\"viridis\")\n",
    "\n",
    "max_freq = df[\"Frequency\"].max()\n",
    "plt.xticks(ticks=range(0, max_freq + 1), labels=range(0, max_freq + 1))\n",
    "\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Protein Annotation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"failed_af3_ligands_functional_keywords.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(f\"{len(failed_ligand_function_annotations)} annotations across all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study PDB statistics of transferases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all CSV files from a custom transferase PDB report\n",
    "transferase_pdb_report_dir = os.path.join(\"pdb_reports\", \"transferase\")\n",
    "transferase_pdb_report_files = [\n",
    "    os.path.join(transferase_pdb_report_dir, f)\n",
    "    for f in os.listdir(transferase_pdb_report_dir)\n",
    "    if f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "transferase_pdb_report_dfs = []\n",
    "for transferase_pdb_report_file in transferase_pdb_report_files:\n",
    "    transferase_pdb_report_dfs.append(pd.read_csv(transferase_pdb_report_file, skiprows=1))\n",
    "transferase_pdb_report_df = pd.concat(transferase_pdb_report_dfs, ignore_index=True)\n",
    "\n",
    "# analyze and plot statistics of the custom transferase PDB report\n",
    "transferase_pdb_report_df[\"Refinement Resolution (Å)\"] = pd.to_numeric(\n",
    "    transferase_pdb_report_df[\"Refinement Resolution (Å)\"].str.replace(\",\", \"\"), errors=\"coerce\"\n",
    ")\n",
    "transferase_pdb_report_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    transferase_pdb_report_df[\"Deposition Date\"]\n",
    ")\n",
    "\n",
    "transferase_pdb_report_df.to_csv(\"transferase_pdb_report.csv\", index=False)\n",
    "\n",
    "sns.histplot(transferase_pdb_report_df[\"Refinement Resolution (Å)\"].values)\n",
    "plt.xlim(0, 10)\n",
    "plt.xlabel(\"Refinement Resolution (Å)\")\n",
    "plt.savefig(\"transferase_pdb_report_resolution.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "sns.histplot(transferase_pdb_report_df[\"Deposition Date\"].values)\n",
    "plt.xlabel(\"Deposition Date\")\n",
    "plt.savefig(\"transferase_pdb_report_deposition_date.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study AlphaFold 3's relationship between training-test set sequence overlap and structure prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PoseBusters Benchmark set and CASP15 ligands that AlphaFold 3 failed to correctly predict\n",
    "for dataset in [\"posebusters_benchmark\", \"casp15\"]:\n",
    "    # NOTE: for DockGen, we consider centroid RMSD (cRMSD) ≤ 1 Å as a surrogate docking success criterion\n",
    "    docking_success_column = \"cRMSD ≤ 1 Å\" if dataset == \"dockgen\" else \"RMSD ≤ 2 Å & PB-Valid\"\n",
    "\n",
    "    for repeat_index in range(1, max_num_repeats_per_method + 1):\n",
    "        dataset_results_table = globals()[f\"results_table_{repeat_index}\"].loc[\n",
    "            (\n",
    "                globals()[f\"results_table_{repeat_index}\"].loc[:, \"dataset\"]\n",
    "                == dataset_mapping[dataset]\n",
    "            )\n",
    "            & (globals()[f\"results_table_{repeat_index}\"].loc[:, \"method\"] == \"AF3\")\n",
    "        ]\n",
    "\n",
    "        if dataset == \"casp15\":\n",
    "            dataset_results_table.loc[:, \"inchi_crystal\"] = (\n",
    "                dataset_results_table.loc[:, \"target\"].astype(str)\n",
    "                + \"_\"\n",
    "                + dataset_results_table.loc[:, \"ref_lig\"].astype(str)\n",
    "            )\n",
    "            dataset_results_table.loc[:, \"pdb_id\"] = dataset_results_table.loc[:, \"target\"].map(\n",
    "                casp15_target_pdb_id_mapping\n",
    "            )\n",
    "\n",
    "        globals()[f\"ligands_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                (dataset_results_table.loc[:, docking_success_column]).astype(bool),\n",
    "                \"inchi_crystal\",\n",
    "            ].unique()\n",
    "        )\n",
    "        globals()[f\"ligands_not_docked_by_af3_{repeat_index}\"] = set(\n",
    "            dataset_results_table.loc[\n",
    "                ~dataset_results_table.loc[:, \"inchi_crystal\"].isin(\n",
    "                    globals()[f\"ligands_docked_by_af3_{repeat_index}\"]\n",
    "                ),\n",
    "                \"inchi_crystal\",\n",
    "            ].unique()\n",
    "        )\n",
    "\n",
    "        # collect metadata of ligands for which the correct (e.g., RMSD ≤ 2 Å & PB-Valid) binding conformation was not found by AlphaFold 3\n",
    "        globals()[f\"{dataset}_overlap_af3_failed_ligands_{repeat_index}\"] = []\n",
    "        for ligand in tqdm(\n",
    "            globals()[f\"ligands_not_docked_by_af3_{repeat_index}\"],\n",
    "            desc=f\"Processing {dataset} AF3 failed ligands\",\n",
    "        ):\n",
    "            ligand_results = dataset_results_table.loc[\n",
    "                dataset_results_table.loc[:, \"inchi_crystal\"] == ligand\n",
    "            ]\n",
    "            row = ligand_results.iloc[0]\n",
    "\n",
    "            if dataset == \"casp15\":\n",
    "                row_inchi = {\n",
    "                    \"name\": row.inchi_crystal,\n",
    "                    \"pdb_id\": row.pdb_id,\n",
    "                }\n",
    "                globals()[f\"{dataset}_overlap_af3_failed_ligands_{repeat_index}\"].append(row_inchi)\n",
    "                continue\n",
    "\n",
    "            row_inchi = CCD_COMPONENTS_INCHI.get(row.inchi_crystal)\n",
    "            if not row_inchi:\n",
    "                # (slowly) find the closest matching CCD component InChI string if necessary (e.g., for DockGen)\n",
    "                closest_inchi, closest_inchi_similarity = find_closest_inchi(\n",
    "                    row.inchi_crystal,\n",
    "                    ccd_components_inchi_keys,\n",
    "                    candidate_fp_cache=ccd_components_inchi_fp_cache,\n",
    "                )\n",
    "                row_inchi = CCD_COMPONENTS_INCHI[closest_inchi]\n",
    "                print(\n",
    "                    f\"Found closest CCD component InChI string (similarity={closest_inchi_similarity}) for: {ligand}\"\n",
    "                )\n",
    "            if row_inchi:\n",
    "                # if row_inchi and row_inchi[\"modified_date\"] > method_max_training_cutoff_date:\n",
    "                print(f\"Failed {dataset_mapping[dataset]} AF3 docking case for: {ligand}\")\n",
    "                print(f\"CCD component InChI metadata: {row_inchi}\\n\")\n",
    "                globals()[f\"{dataset}_overlap_af3_failed_ligands_{repeat_index}\"].append(row_inchi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot deposition dates of proteins most similar to AlphaFold 3's failed PoseBusters Benchmark set complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot max sequence overlap deposition dates of AlphaFold 3's failed PoseBusters Benchmark set and CASP15 complexes\n",
    "pd.options.mode.copy_on_write = False\n",
    "\n",
    "af3_overlap_datasets = [\"posebusters_benchmark\", \"casp15\"]\n",
    "\n",
    "all_af3_failed_ligands_df = []\n",
    "for dataset in af3_overlap_datasets:\n",
    "    for repeat_index in [1]:  # NOTE: for now, we only consider the first repeat\n",
    "        failed_ligands_df = pd.DataFrame(\n",
    "            globals()[f\"{dataset}_overlap_af3_failed_ligands_{repeat_index}\"]\n",
    "        )\n",
    "        failed_ligands_df[\"dataset\"] = dataset_mapping[dataset]\n",
    "        failed_ligands_df[\"repeat_index\"] = repeat_index\n",
    "        all_af3_failed_ligands_df.append(failed_ligands_df)\n",
    "all_af3_failed_ligands_df = pd.concat(all_af3_failed_ligands_df, ignore_index=True)\n",
    "all_af3_failed_ligand_pdb_ids = list(all_af3_failed_ligands_df.loc[:, \"pdb_id\"].unique())\n",
    "\n",
    "# prepare target and database FASTA files\n",
    "target_fasta = \"target.fasta\"\n",
    "database_fasta = os.path.join(\"..\", \"data\", \"pdb_data\", \"pdb_seqres.txt\")\n",
    "\n",
    "# parse PDB sequences\n",
    "pdb_sequences = parse_fasta(\n",
    "    database_fasta,\n",
    "    only_mols=[\"protein\"],\n",
    "    collate_by_pdb_id=True,\n",
    ")\n",
    "\n",
    "with open(target_fasta, \"w\") as target_f:\n",
    "    for pdb_id in all_af3_failed_ligand_pdb_ids:\n",
    "        if pdb_id.lower() in pdb_sequences:\n",
    "            for seq in pdb_sequences[pdb_id.lower()]:\n",
    "                target_f.write(f\">{pdb_id.lower()}_{seq[0]}\\n{seq[-1]}\\n\")\n",
    "\n",
    "# run MMseqs2 to find the best match for each PDB chain\n",
    "result_file = \"result.m8\"\n",
    "tmp_dir = \"mmseqs_tmp\"\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"mmseqs\",\n",
    "        \"easy-search\",\n",
    "        target_fasta,\n",
    "        database_fasta,\n",
    "        result_file,\n",
    "        tmp_dir,\n",
    "        \"--format-output\",\n",
    "        \"query,target,pident,qcov,tcov,evalue,bits\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# parse MMseqs2 top match for each PDB chain\n",
    "query_top_match_pdb_id_mappings = dict()\n",
    "if os.path.exists(result_file):\n",
    "    with open(result_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            query_pdb_id = line.strip().split(\"\\t\")[0]\n",
    "            top_match_pdb_id = line.strip().split(\"\\t\")[1]\n",
    "            if (\n",
    "                query_pdb_id not in query_top_match_pdb_id_mappings\n",
    "                and query_pdb_id.split(\"_\")[0] != top_match_pdb_id.split(\"_\")[0]\n",
    "            ):\n",
    "                query_top_match_pdb_id_mappings[query_pdb_id] = top_match_pdb_id\n",
    "\n",
    "    all_af3_failed_ligand_pdb_ids = list(query_top_match_pdb_id_mappings.keys())\n",
    "    top_match_pdb_ids = list(query_top_match_pdb_id_mappings.values())\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"No results found. Ensure MMseqs2 is correctly installed and the input sequences are valid.\"\n",
    "    )\n",
    "\n",
    "os.remove(target_fasta)\n",
    "os.remove(result_file)\n",
    "shutil.rmtree(tmp_dir)\n",
    "\n",
    "# find the deposition dates of failed ligands and their top matches\n",
    "failed_ligands = []\n",
    "failed_ligand_indices = set()\n",
    "failed_ligands_after_cutoff_deposition_date = []\n",
    "failed_ligands_after_cutoff_deposition_date_indices = set()\n",
    "for failed_ligand_index, failed_ligand_pdb_id in enumerate(all_af3_failed_ligand_pdb_ids):\n",
    "    failed_ligand_pdb_id_ = failed_ligand_pdb_id.lower().split(\"_\")[0]\n",
    "    if failed_ligand_pdb_id_ == \"?\":\n",
    "        continue\n",
    "    if failed_ligand_pdb_id_ in pdb_info_cache:\n",
    "        failed_ligand_pdb_info = pdb_info_cache[failed_ligand_pdb_id_]\n",
    "    else:\n",
    "        failed_ligand_pdb_info = pypdb.get_all_info(failed_ligand_pdb_id_)\n",
    "        pdb_info_cache[failed_ligand_pdb_id_] = failed_ligand_pdb_info\n",
    "    if not failed_ligand_pdb_info:\n",
    "        continue\n",
    "    deposition_date = failed_ligand_pdb_info[\"rcsb_accession_info\"][\"deposit_date\"]\n",
    "    failed_ligand_indices.add(failed_ligand_index)\n",
    "    failed_ligands.append((failed_ligand_pdb_id_, deposition_date))\n",
    "    if deposition_date > method_max_training_cutoff_date:\n",
    "        failed_ligands_after_cutoff_deposition_date_indices.add(failed_ligand_index)\n",
    "        failed_ligands_after_cutoff_deposition_date.append(\n",
    "            (failed_ligand_pdb_id_, deposition_date)\n",
    "        )\n",
    "\n",
    "top_match_complexes = []\n",
    "top_match_complexes_after_cutoff_deposition_date = []\n",
    "for top_match_index, top_match_pdb_id in enumerate(top_match_pdb_ids):\n",
    "    top_match_pdb_id_ = top_match_pdb_id.lower().split(\"_\")[0]\n",
    "    if top_match_pdb_id_ == \"?\":\n",
    "        continue\n",
    "    if top_match_index not in failed_ligand_indices:\n",
    "        continue\n",
    "    if top_match_pdb_id_ in pdb_info_cache:\n",
    "        top_match_pdb_info = pdb_info_cache[top_match_pdb_id_]\n",
    "    else:\n",
    "        top_match_pdb_info = pypdb.get_all_info(top_match_pdb_id_)\n",
    "        pdb_info_cache[top_match_pdb_id_] = top_match_pdb_info\n",
    "    if not top_match_pdb_info:\n",
    "        continue\n",
    "    deposition_date = top_match_pdb_info[\"rcsb_accession_info\"][\"deposit_date\"]\n",
    "    top_match_complexes.append((top_match_pdb_id_, deposition_date))\n",
    "    if top_match_index in failed_ligands_after_cutoff_deposition_date_indices:\n",
    "        top_match_complexes_after_cutoff_deposition_date.append(\n",
    "            (top_match_pdb_id_, deposition_date)\n",
    "        )\n",
    "\n",
    "assert len(failed_ligands) == len(\n",
    "    top_match_complexes\n",
    "), \"Expected equal number of failed ligands and top matches.\"\n",
    "assert len(failed_ligands_after_cutoff_deposition_date) == len(\n",
    "    top_match_complexes_after_cutoff_deposition_date\n",
    "), \"Expected equal number of failed ligands and top matches after the cutoff deposition date.\"\n",
    "\n",
    "# analyze and plot statistics of the failed ligands and their top matches' deposition dates\n",
    "failed_ligand_pdb_deposition_dates_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Deposition Date\": [lig[1] for lig in list(dict.fromkeys(failed_ligands))]\n",
    "    }  # remove chain duplicates in-order\n",
    ")\n",
    "failed_ligand_pdb_deposition_dates_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    failed_ligand_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    ")\n",
    "failed_ligand_pdb_deposition_dates_df.to_csv(\n",
    "    \"af3_failed_ligand_pdb_deposition_dates.csv\", index=False\n",
    ")\n",
    "sns.histplot(failed_ligand_pdb_deposition_dates_df[\"Deposition Date\"].values, bins=25)\n",
    "plt.xlabel(\"Deposition Date\")\n",
    "plt.savefig(\"af3_failed_ligand_pdb_deposition_dates.png\")\n",
    "plt.show()\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(\n",
    "    f\"{len(failed_ligand_pdb_deposition_dates_df)} date annotations across {af3_overlap_datasets}.\"\n",
    ")\n",
    "\n",
    "top_match_pdb_deposition_dates_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Deposition Date\": [com[1] for com in list(dict.fromkeys(top_match_complexes))]\n",
    "    }  # remove chain duplicates in-order\n",
    ")\n",
    "top_match_pdb_deposition_dates_df[\"Deposition Date\"] = pd.to_datetime(\n",
    "    top_match_pdb_deposition_dates_df[\"Deposition Date\"]\n",
    ")\n",
    "top_match_pdb_deposition_dates_df.to_csv(\n",
    "    \"af3_failed_ligand_top_match_pdb_deposition_dates.csv\", index=False\n",
    ")\n",
    "sns.histplot(top_match_pdb_deposition_dates_df[\"Deposition Date\"].values, bins=30)\n",
    "plt.xlabel(\"Deposition Date\")\n",
    "plt.savefig(\"af3_failed_ligand_top_match_pdb_deposition_dates.png\")\n",
    "plt.show()\n",
    "plt.close(\"all\")\n",
    "\n",
    "print(\n",
    "    f\"{len(top_match_pdb_deposition_dates_df)} top match date annotations across {af3_overlap_datasets}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify specific complexes AlphaFold 3 failed to predict that are worth studying further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for failed ligands and their top matches that were both deposited after the cutoff deposition date\n",
    "collated_ligands = defaultdict(list)\n",
    "for ligand, top_match_complex in zip(\n",
    "    failed_ligands_after_cutoff_deposition_date, top_match_complexes_after_cutoff_deposition_date\n",
    "):\n",
    "    ligand_pdb_id = ligand[0]\n",
    "    top_match_pdb_id = top_match_complex[0]\n",
    "    ligand_deposition_date = ligand[1]\n",
    "    top_match_complex_deposition_date = top_match_complex[1]\n",
    "    collated_ligand = (\n",
    "        (ligand_pdb_id, ligand_deposition_date),\n",
    "        (top_match_pdb_id, top_match_complex_deposition_date),\n",
    "    )\n",
    "    collated_ligands[ligand_pdb_id].append(collated_ligand)\n",
    "\n",
    "failed_ligands_to_study_further = []\n",
    "for ligand_pdb_id in collated_ligands:\n",
    "    collated_ligand_chains = collated_ligands[ligand_pdb_id]\n",
    "    all_chains_after_cutoff_deposition_date = True\n",
    "    for collated_ligand_chain in collated_ligand_chains:\n",
    "        (ligand_pdb_id, ligand_deposition_date), (\n",
    "            top_match_pdb_id,\n",
    "            top_match_complex_deposition_date,\n",
    "        ) = collated_ligand_chain\n",
    "        if (\n",
    "            ligand_deposition_date <= method_max_training_cutoff_date\n",
    "            or top_match_complex_deposition_date <= method_max_training_cutoff_date\n",
    "        ):\n",
    "            all_chains_after_cutoff_deposition_date = False\n",
    "            break\n",
    "    if all_chains_after_cutoff_deposition_date:\n",
    "        failed_ligands_to_study_further.append(collated_ligand_chains)\n",
    "        print(f\"{ligand_pdb_id}: {collated_ligand_chains}\")\n",
    "\n",
    "print(\n",
    "    f\"{len(failed_ligands_to_study_further)} ((ligand, deposition date), (top match, deposition date)) novel protein-ligand PDB complexes AlphaFold 3 failed to predict that are worth studying further.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoseBench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
